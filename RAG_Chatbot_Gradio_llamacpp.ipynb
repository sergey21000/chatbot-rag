{"cells":[{"cell_type":"markdown","source":["---\n","**–ß–∞—Ç-–±–æ—Ç —Å –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º –Ω–∞ `Gradio` –∏ –º–µ—Ö–∞–Ω–∏–∑–º–æ–º RAG —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫ `llama-cpp-python` –∏ `langchain`**"],"metadata":{"id":"r0V39CdhHzhY"}},{"cell_type":"markdown","metadata":{"id":"IOLcB9b1wHam"},"source":["---\n","RAG (Retrieval Augmented Generation) ‚Äî –ø—Ä–æ—Å—Ç–æ–µ –∏ –ø–æ–Ω—è—Ç–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç—å—è  \n","https://habr.com/ru/articles/779526/\n","\n","–í–µ–∫—Ç–æ—Ä–Ω—ã–µ –ë–î —Å—Ç–∞—Ç—å–∏  \n","https://habr.com/ru/articles/807957/  \n","https://habr.com/ru/articles/817173/\n","https://habr.com/ru/articles/784158/\n","\n","RAG —Å—Ç–∞—Ç—å–∏  \n","https://habr.com/ru/companies/wunderfund/articles/779748/  \n","https://habr.com/ru/companies/bothub/articles/825850/  \n","https://www.promptingguide.ai/research/rag?utm_source=substack&utm_medium=email  \n","https://vinija.ai/nlp/RAG/  \n","https://www.rungalileo.io/blog/mastering-rag-how-to-architect-an-enterprise-rag-system  \n","\n","–¢—É—Ç–æ—Ä–∏–∞–ª –ø–æ RAG –æ—Ç HF  \n","https://huggingface.co/learn/cookbook/advanced_rag\n","\n","–¢—É—Ç–æ—Ä–∏–∞–ª—ã –ø–æ langchain –∏ RAG  \n","https://blog.davideai.dev/series/langchain  \n","https://habr.com/ru/articles/729664/  \n","\n","–ö—É—Ä—Å Building Agentic RAG with LlamaIndex  \n","https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex/\n","\n","–ö–æ–º–ø–∞–∫—Ç–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è RAG —á–µ—Ä–µ–∑ Ollama  \n","https://github.com/technovangelist/videoprojects/tree/main/2024-04-04-build-rag-with-python  \n","–í–∏–¥–µ–æ –ø—Ä–æ RAG –≥–¥–µ –æ–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è (RU)  \n","https://www.youtube.com/watch?v=DyOKAVzMWaQ\n","\n","\n","---"]},{"cell_type":"markdown","source":["# –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞"],"metadata":{"id":"A7w7hpUsKpM1"}},{"cell_type":"markdown","source":["–ö–æ–¥ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (–Ω–µ –¥–ª—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤ Colab)"],"metadata":{"id":"WY4-lIAnkaPP"}},{"cell_type":"markdown","source":["**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞:**\n","\n"," - üìÅ `models`\n"," - üìÅ `embed_models`\n"," - `requirements-base.txt`\n"," - `requirements-cpu.txt`\n"," - `requirements-cuda.txt`\n"," - `app.py`\n"," - `models.py`\n"," - `utils.py`\n"],"metadata":{"id":"IASD77EW1_G3"}},{"cell_type":"markdown","source":["**–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∑–∞–ø—É—Å–∫:**\n","\n","1) –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏—è –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n","\n"," –°–æ–∑–¥–∞–Ω–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:\n"," ```\n","python3 -m venv env\n"," ```\n"," –ê–∫—Ç–∏–≤–∞—Ü–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è:\n"," - Linux\n","```\n","source env/bin/activate\n","```\n","\n"," - Windows\n","```\n","env\\Scripts\\activate.bat\n","```\n","\n","2) –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫\n"," - —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CPU\n"," ```\n"," pip install -r requirements-cpu.txt\n"," ```\n","\n"," - —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA\n"," ```\n"," pip install -r requirements-cuda.txt\n"," ```\n","\n","–î–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ `llama-cpp-python` –Ω–∞ Windows —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA –Ω—É–∂–Ω–æ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å [Visual Studio 2022 Community](https://visualstudio.microsoft.com/ru/downloads/) –∏ [CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit-archive), –∫–∞–∫ –Ω–∞–ø—Ä–∏–º–µ—Ä —É–∫–∞–∑–∞–Ω–æ –≤ —ç—Ç–æ–π [–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏](https://github.com/abetlen/llama-cpp-python/discussions/871#discussion-5812096)  \n","–î–ª—è –ø–æ–ª–Ω–æ–π –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–º–∞–Ω–¥—É\n","```\n","pip install --force-reinstall --no-cache-dir -r requirements.txt --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124\n","```\n","\n","–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ [llama-cpp-python](https://github.com/abetlen/llama-cpp-python?tab=readme-ov-file#installation-configuration) –∏ [torch](https://pytorch.org/get-started/locally/#start-locally) –¥–ª—è –¥—Ä—É–≥–∏—Ö –≤–µ—Ä—Å–∏–π –∏ —Å–∏—Å—Ç–µ–º\n","\n","3) –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è\n","```\n","python3 app.py\n","```\n"," –ü–µ—Ä–µ–π—Ç–∏ –≤ –±—Ä–∞—É–∑–µ—Ä–µ http://localhost:7860/ –ø–æ—Å–ª–µ —Ç–æ–≥–æ –∫–∞–∫ –ø–æ—è–≤–∏—Ç—Å—è –Ω–∞–¥–ø–∏—Å—å `Running on local URL:  http://127.0.0.1:7860`"],"metadata":{"id":"JnLtJ518xLrE"}},{"cell_type":"markdown","source":["**–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤ `requirements:`**\n","\n","`requirements-base.txt`\n","```\n","gradio==5.0.1\n","langchain==0.3.3\n","langchain-community==0.3.1\n","langchain-huggingface==0.1.0\n","pdfminer.six==20240706\n","youtube-transcript-api==0.6.2\n","psutil==6.0.0\n","faiss-cpu==1.9.0\n","beautifulsoup4==4.12.3\n","```\n","\n","`requirements-cpu.txt`\n","```\n","--extra-index-url https://download.pytorch.org/whl/cpu\n","--extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu\n","torch==2.4.1\n","llama_cpp_python==0.2.90\n","-r requirements-base.txt\n","```\n","\n","`requirements-cuda.txt`\n","```\n","--extra-index-url https://download.pytorch.org/whl/cu125\n","--extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124\n","torch==2.4.1\n","llama_cpp_python==0.2.90\n","-r requirements-base.txt\n","```\n","\n","–ï—Å–ª–∏ –≤ —Å–∏—Å—Ç–µ–º–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ CUDA –Ω–µ 12 –∞ 11 –≤–µ—Ä—Å–∏–∏ - –∑–∞–º–µ–Ω–∏—Ç—å –≤ `requirements-cuda.txt`  \n","`https://download.pytorch.org/whl/cu124`  \n","–Ω–∞  \n","`https://download.pytorch.org/whl/cu118`  \n","–¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —É—Å—Ç–∞–Ω–æ–∫–∏ Pytorch\n","\n","–ü–∞–ø–∫–∞ `env` —Å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏ –¥–ª—è CPU –∑–∞–Ω–∏–º–∞–µ—Ç 1,90 Gb"],"metadata":{"id":"ix3buTO-yK_M"}},{"cell_type":"markdown","source":["–°–æ–¥–µ—Ä–∂–∏–º–æ–µ `requirements.txt` –¥–ª—è –¥–µ–ø–ª–æ—è –Ω–∞ HF  \n","```\n","--extra-index-url https://download.pytorch.org/whl/cpu\n","torch==2.4.1\n","llama_cpp_python==0.2.90\n","gradio==5.0.1\n","langchain==0.3.3\n","langchain-community==0.3.1\n","langchain-huggingface==0.1.0\n","pdfminer.six==20240706\n","youtube-transcript-api==0.6.2\n","psutil==6.0.0\n","faiss-cpu==1.9.0\n","beautifulsoup4==4.12.3\n","```\n","–ó–¥–µ—Å—å `llama_cpp_python` —Å—Ç–∞–≤–∏—Ç—Å—è –∫–∞–∫ –æ–±—ã—á–Ω–æ –ø–æ—Ç–æ–º—É —á—Ç–æ –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ —á–µ—Ä–µ–∑ `--extra-index-url` –≤—ã–¥–∞–µ—Ç –æ—à–∏–±–∫—É   \n","`Failed to load shared library '/usr/local/lib/python3.10/site-packages/llama_cpp/lib/libllama.so': libc.musl-x86_64.so.1: cannot open shared object fil`  "],"metadata":{"id":"gNNMCXvFgGF6"}},{"cell_type":"markdown","source":["# –ü–æ–ª–Ω—ã–π –∫–æ–¥ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏ –∑–∞–ø—É—Å–∫ –≤ Colab/Jupyter"],"metadata":{"id":"o18AOcSERr5l"}},{"cell_type":"markdown","metadata":{"id":"PVEAYBZ1Cis-"},"source":["## –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫"]},{"cell_type":"markdown","source":["–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫"],"metadata":{"id":"Xd0yt9DWas15"}},{"cell_type":"markdown","source":["–°—Ç—Ä–∞–Ω–∏—Ü–∞ GiHub langchain  \n","https://github.com/langchain-ai/langchain"],"metadata":{"id":"MYif49Dd6zB7"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"daee4813-1220-433c-8e19-fc4050ab7013","id":"K8IwiJj67sAj","executionInfo":{"status":"ok","timestamp":1728636688242,"user_tz":-180,"elapsed":41223,"user":{"displayName":"–°–µ—Ä–≥–µ–π","userId":"08873757262896960569"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 360 ms, sys: 96.2 ms, total: 456 ms\n","Wall time: 41.2 s\n"]}],"source":["%%time\n","%%capture\n","\n","# faiss-cpu or faiss-gpu\n","!pip install langchain langchain_community langchain_huggingface \\\n","    pdfminer.six gradio youtube-transcript-api faiss-cpu psutil"]},{"cell_type":"markdown","metadata":{"id":"C8qmQjH3aoA3"},"source":["–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ llama-cpp-python"]},{"cell_type":"markdown","metadata":{"id":"6tkbi6lUaoAp"},"source":["–î–æ–∫–∏ llama-cpp-python  \n","https://llama-cpp-python.readthedocs.io/en/latest/?badge=latest  \n","–°—Ç—Ä–∞–Ω–∏—Ü–∞ Githib llama-cpp-python   \n","https://github.com/abetlen/llama-cpp-python\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e1ed1209-99b5-4cae-ac3e-e9aa9df1b58f","id":"dMWPWpq7aoA3","executionInfo":{"status":"ok","timestamp":1728636916471,"user_tz":-180,"elapsed":228236,"user":{"displayName":"–°–µ—Ä–≥–µ–π","userId":"08873757262896960569"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.8/63.8 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["# —É—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CPU\n","!pip install -q llama-cpp-python==0.2.90\n","\n","# —É—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π GPU CUDA\n","# !CMAKE_ARGS='-DGGML_CUDA=on' FORCE_CMAKE=1 pip install llama-cpp-python"]},{"cell_type":"markdown","source":["–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–π –±–∏–±–ª–∏–æ—Ç–µ–∫"],"metadata":{"id":"X2txYs72ChvG"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"890f1085-8fc3-4c8f-8107-4905f3544e5e","id":"dUy5vQWP7sAk","executionInfo":{"status":"ok","timestamp":1728636917672,"user_tz":-180,"elapsed":1209,"user":{"displayName":"–°–µ—Ä–≥–µ–π","userId":"08873757262896960569"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["beautifulsoup4                     4.12.3\n","faiss-cpu                          1.9.0\n","gradio                             5.0.1\n","gradio_client                      1.4.0\n","huggingface-hub                    0.25.2\n","langchain                          0.3.3\n","langchain-community                0.3.2\n","langchain-core                     0.3.10\n","langchain-huggingface              0.1.0\n","langchain-text-splitters           0.3.0\n","llama_cpp_python                   0.2.90\n","pdfminer.six                       20240706\n","sentence-transformers              3.2.0\n","torch                              2.4.1+cu121\n","torchaudio                         2.4.1+cu121\n","torchsummary                       1.5.1\n","torchvision                        0.19.1+cu121\n","transformers                       4.44.2\n","youtube-transcript-api             0.6.2\n"]}],"source":["!pip list | grep -P 'torch|langchain|transformers|llama_cpp|gradio|youtube|huggingface-hub|pdfminer.six|faiss|beautifulsoup4'"]},{"cell_type":"code","source":["# –≤–µ—Ä—Å–∏—è Python\n","!python -V"],"metadata":{"id":"f83AaouSOwhl","colab":{"base_uri":"https://localhost:8080/"},"outputId":"26b87287-4916-4571-e235-31ce4a891bb5","executionInfo":{"status":"ok","timestamp":1728636918253,"user_tz":-180,"elapsed":584,"user":{"displayName":"–°–µ—Ä–≥–µ–π","userId":"08873757262896960569"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.12\n"]}]},{"cell_type":"markdown","source":["## –§—É–Ω–∫—Ü–∏–∏"],"metadata":{"id":"6m1t2-GdKj_B"}},{"cell_type":"markdown","source":["–ú–æ–¥—É–ª—å `utils.py`"],"metadata":{"id":"oaureeJOUkZ4"}},{"cell_type":"code","source":["import csv\n","from pathlib import Path\n","from shutil import rmtree\n","from typing import List, Tuple, Dict, Union, Optional, Any, Iterable\n","from tqdm import tqdm\n","\n","import psutil\n","import requests\n","from requests.exceptions import MissingSchema\n","\n","import torch\n","import gradio as gr\n","\n","from llama_cpp import Llama\n","from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, TranscriptsDisabled\n","from huggingface_hub import hf_hub_download, list_repo_tree, list_repo_files, repo_info, repo_exists, snapshot_download\n","\n","from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n","from langchain_community.vectorstores import FAISS\n","from langchain_huggingface import HuggingFaceEmbeddings\n","\n","# imports for annotations\n","from langchain.docstore.document import Document\n","from langchain_core.embeddings import Embeddings\n","from langchain_core.vectorstores import VectorStore\n","\n","# from config import (\n","#     LLM_MODELS_PATH,\n","#     EMBED_MODELS_PATH,\n","#     GENERATE_KWARGS,\n","#     LOADER_CLASSES,\n","#     CONTEXT_TEMPLATE,\n","# )\n","\n","\n","# –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏\n","CHAT_HISTORY = List[Optional[Dict[str, Optional[str]]]]\n","LLM_MODEL_DICT = Dict[str, Llama]\n","EMBED_MODEL_DICT = Dict[str, Embeddings]\n","\n","\n","# ===================== –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò =======================\n","\n","# –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–≤–æ–±–æ–¥–Ω–æ–π –ø–∞–º—è—Ç–∏ –Ω–∞ –¥–∏—Å–∫–µ, CPU –∏ GPU\n","def get_memory_usage() -> str:\n","    print_memory = ''\n","\n","    memory_type = 'Disk'\n","    psutil_stats = psutil.disk_usage('.')\n","    memory_total = psutil_stats.total / 1024**3\n","    memory_usage = psutil_stats.used / 1024**3\n","    print_memory += f'{memory_type} Menory Usage: {memory_usage:.2f} / {memory_total:.2f} GB\\n'\n","\n","    memory_type = 'CPU'\n","    psutil_stats = psutil.virtual_memory()\n","    memory_total = psutil_stats.total / 1024**3\n","    memory_usage =  memory_total - (psutil_stats.available / 1024**3)\n","    print_memory += f'{memory_type} Menory Usage: {memory_usage:.2f} / {memory_total:.2f} GB\\n'\n","\n","    if torch.cuda.is_available():\n","        memory_type = 'GPU'\n","        memory_free, memory_total = torch.cuda.mem_get_info()\n","        memory_usage = memory_total - memory_free\n","        print_memory += f'{memory_type} Menory Usage: {memory_usage / 1024**3:.2f} / {memory_total:.2f} GB\\n'\n","\n","    print_memory = f'---------------\\n{print_memory}---------------'\n","    return print_memory\n","\n","\n","# –æ—á–∏—Å—Ç–∫–∞ —Å–ø–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n","def clear_documents(documents: Iterable[Document]) -> Iterable[Document]:\n","    # –æ—á–∏—Å—Ç–∫–∞ —Å—Ç—Ä–æ–∫–∏ —Ç–µ–∫—Å—Ç–∞\n","    def clear_text(text: str) -> str:\n","        lines = text.split('\\n')\n","        # –±—Ä–∞—Ç—å —Å—Ç—Ä–æ–∫–∏, –∫–æ–ª-–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ –≤ –∫–æ—Ç–æ—Ä—ã—Ö –±–æ–ª—å—à–µ 2\n","        lines = [line for line in lines if len(line.strip()) > 2]\n","        text = '\\n'.join(lines).strip()\n","        return text\n","\n","    # –∏—Ç–µ—Ä–∞—Ü–∏—è –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –∏ –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞\n","    output_documents = []\n","    for document in documents:\n","        # –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Ç–µ–∫—É—â–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞\n","        text = clear_text(document.page_content)\n","        # –±–µ—Ä–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –¥–ª–∏–Ω–æ–π —Ç–µ–∫—Å—Ç–∞ –±–æ–ª–µ–µ 1\n","        if len(text) > 10:\n","            # –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –æ–±—Ä–∞—Ç–Ω–æ –≤ –¥–æ–∫—É–º–µ–Ω—Ç –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫\n","            document.page_content = text\n","            output_documents.append(document)\n","    return output_documents\n","\n","\n","# ===================== –§–£–ù–ö–¶–ò–ò –ò–ù–¢–ï–†–§–ï–ô–°–ê =============================\n","\n","\n","# ------------- –ó–ê–ì–†–£–ó–ö–ê LLM –ò –≠–ú–ë–ï–î–ò–ù–ì –ú–û–î–ï–õ–ï–ô ------------------------\n","\n","# —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ –ø–æ URL —Å—Å—ã–ª–∫–µ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä–æ–≤ tqdm –∏ gradio\n","def download_file(file_url: str, file_path: Union[str, Path]) -> None:\n","    response = requests.get(file_url, stream=True)\n","    if response.status_code != 200:\n","        raise Exception(f'–§–∞–π–ª –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –ø–æ —Å—Å—ã–ª–∫–µ: {file_url}')\n","    # –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞ –≤ –±–∞–π—Ç–∞—Ö\n","    total_size = int(response.headers.get('content-length', 0))\n","    # –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä tqdm\n","    progress_tqdm = tqdm(desc='–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ GGUF', total=total_size, unit='iB', unit_scale=True)\n","    # –ø—Ä–æ–≥—Ä–µ–º–º –±–∞—Ä Gradio\n","    progress_gradio = gr.Progress()\n","    # —Å—á–µ—Ç—á–∏–∫ –∫–æ–ª-–≤–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –±–∞–π—Ç–æ–≤\n","    completed_size = 0\n","    # –æ—Ç–∫—Ä—ã—Ç–∏–µ —Ñ–∞–π–ª–∞ –Ω–∞ –∑–∞–ø–∏—Å—å\n","    with open(file_path, 'wb') as file:\n","        # –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —á–∞–Ω–∫–∞–º–∏ –ø–æ 4–ö–± –∏ –∑–∞–ø–∏—Å—å —á–∞–Ω–∫–∞ –≤ —Ñ–∞–π–ª\n","        for data in response.iter_content(chunk_size=4096):\n","            size = file.write(data)\n","            # –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä–∞ tqdm\n","            progress_tqdm.update(size)\n","            # # –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä–∞ Gradio\n","            completed_size += size\n","            desc = f'–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ GGUF, {completed_size/1024**3:.3f}/{total_size/1024**3:.3f} GB'\n","            progress_gradio(completed_size/total_size, desc=desc)\n","\n","\n","# –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ GGUF\n","def load_llm_model(model_repo: str, model_file: str) -> Tuple[LLM_MODEL_DICT, str, str]:\n","    # –º–æ–¥–µ–ª—å LLM, –ª–æ–≥–∏ –∑–∞–≥—Ä—É–∑–∫–∏\n","    llm_model = None\n","    load_log = ''\n","    support_system_role = False\n","\n","    # –µ—Å–ª–∏ –Ω–∏ –æ–¥–∏–Ω –ø—É–∫—Ç –Ω–µ –≤—ã–±—Ä–∞–Ω –≤ –≤—ã–ø–∞–¥–∞—é—â–µ–º —Å–ø–∏—Å–∫–∏ —Å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è–º–∏ HF\n","    if isinstance(model_file, list):\n","        load_log += '–ù–µ –≤—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å\\n'\n","        return {'llm_model': llm_model}, support_system_role, load_log\n","\n","    # –µ—Å–ª–∏ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞ GGUF –µ—Å—Ç—å —Å–∫–æ–±–∫–∞ (–≤ —Å–∫–æ–±–∫–∞—Ö —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏)\n","    if '(' in model_file:\n","        model_file = model_file.split('(')[0].rstrip()\n","\n","    # –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä Gradio\n","    progress = gr.Progress()\n","    progress(0.3, desc='–®–∞–≥ 1/2: –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ GGUF')\n","    # –∏—Ç–æ–≥–æ–≤—ã–π –ø—É—Ç—å –∫—É–¥–∞ –Ω–∞–¥–æ —Å–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å (—Ñ–∞–π–ª GGUF)\n","    model_path = LLM_MODELS_PATH / model_file\n","\n","    # –µ—Å–ª–∏ —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω\n","    if model_path.is_file():\n","        load_log += f'–ú–æ–¥–µ–ª—å {model_file} —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è\\n'\n","    else:\n","        # –ø–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏ GGUF\n","        try:\n","            # hf_hub_download(\n","            #     repo_id=model_repo,\n","            #     filename=model_file,\n","            #     local_dir=LLM_MODELS_PATH,\n","            #     )\n","            # –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä–æ–º\n","            gguf_url = f'https://huggingface.co/{model_repo}/resolve/main/{model_file}'\n","            download_file(gguf_url, model_path)\n","            load_log += f'–ú–æ–¥–µ–ª—å {model_file} –∑–∞–≥—Ä—É–∂–µ–Ω–∞\\n'\n","        # –µ—Å–ª–∏ –æ—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∑–∞–≥—Ä—É–∑–∫–∏\n","        except Exception as ex:\n","            model_path = ''\n","            load_log += f'–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏, –∫–æ–¥ –æ—à–∏–±–∫–∏:\\n{ex}\\n'\n","\n","    # –µ—Å–ª–∏ —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —Ç–æ –Ω—É–∂–Ω–æ –µ–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å\n","    if model_path:\n","        progress(0.7, desc='–®–∞–≥ 2/2: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏')\n","        try:\n","            # –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ (—É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å verbose=True –¥–ª—è –≤—ã–≤–æ–¥–∞ —Å—Ç–∞—Ç—É—Å–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏)\n","            llm_model = Llama(model_path=str(model_path), n_gpu_layers=-1, verbose=False)\n","            # –ø–æ–ª—É—á–µ–Ω–∏–µ —Ñ–ª–∞–≥–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –º–æ–¥–µ–ª—å—é —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º—Ç–∞\n","            support_system_role = 'System role not supported' not in llm_model.metadata['tokenizer.chat_template']\n","            # –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –º–æ–¥–µ–ª–∏\n","            load_log += f'–ú–æ–¥–µ–ª—å {model_file} –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞, –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ - {llm_model.n_ctx()} —Ç–æ–∫–µ–Ω–æ–≤\\n'\n","        except Exception as ex:\n","            load_log += f'–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏, –∫–æ–¥ –æ—à–∏–±–∫–∏:\\n{ex}\\n'\n","\n","    llm_model = {'llm_model': llm_model}\n","    return llm_model, support_system_role, load_log\n","\n","\n","# –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤\n","def load_embed_model(model_repo: str) -> Tuple[Dict[str, HuggingFaceEmbeddings], str]:\n","    # –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ –∏ –ª–æ–≥–∏ –∑–∞–≥—Ä—É–∑–∫–∏\n","    embed_model = None\n","    load_log = ''\n","\n","    # –µ—Å–ª–∏ –Ω–∏ –æ–¥–∏–Ω –ø—É–∫—Ç –Ω–µ –≤—ã–±—Ä–∞–Ω –≤ –≤—ã–ø–∞–¥–∞—é—â–µ–º —Å–ø–∏—Å–∫–∏ —Å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è–º–∏ HF\n","    if isinstance(model_repo, list):\n","        load_log = '–ù–µ –≤—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å'\n","        return embed_model, load_log\n","\n","    # –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä Gradio\n","    progress = gr.Progress()\n","    # –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π –∏–∑ HF –∏—Ö –ø–∞–ø–∫–∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞—é—Ç—Å—è –∏–∑ USER_NAME/REPO_NAME –≤ USER_NAME_REPO_NAME\n","    folder_name = model_repo.replace('/', '_')\n","    # –∏—Ç–æ–≥–æ–≤—ã–π –ø—É—Ç—å –∫—É–¥–∞ –Ω–∞–¥–æ —Å–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å (–ø–∞–ø–∫–∞ —Å –º–æ–¥–µ–ª—å—é)\n","    folder_path = EMBED_MODELS_PATH / folder_name\n","    # –µ—Å–ª–∏ –ø–∞–ø–∫–∞ —Å –º–æ–¥–µ–ª—å—é —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞\n","    if Path(folder_path).is_dir():\n","        load_log += f'–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ {model_repo} \\n'\n","    # –∏–Ω–∞—á–µ –º–æ–¥–µ–ª—å –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å\n","    else:\n","        progress(0.5, desc='–®–∞–≥ 1/2: –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –º–æ–¥–µ–ª–∏')\n","        snapshot_download(\n","            repo_id=model_repo,\n","            local_dir=folder_path,\n","            ignore_patterns='*.h5',\n","        )\n","        load_log += f'–ú–æ–¥–µ–ª—å {model_repo} –∑–∞–≥—Ä—É–∂–µ–Ω–∞ \\n'\n","\n","    # –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤\n","    progress(0.7, desc='–®–∞–≥ 2/2: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏')\n","    model_kwargs = {'device': 'cuda' if torch.cuda.is_available() else 'cpu'}\n","    embed_model = HuggingFaceEmbeddings(\n","        model_name=str(folder_path),\n","        model_kwargs=model_kwargs,\n","        # encode_kwargs={'normalize_embeddings': True},\n","        )\n","    load_log += f'–ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ {model_repo} –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞\\n'\n","    load_log += f'–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –ë–î –∑–∞–Ω–æ–≤–æ\\n'\n","    embed_model = {'embed_model': embed_model}\n","    return embed_model, load_log\n","\n","\n","# –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–æ–≤–æ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è HF new_model_repo –∫ —Ç–µ–∫—É—â–µ–º—É —Å–ø–∏—Å–∫—É model_repos\n","def add_new_model_repo(new_model_repo: str, model_repos: List[str]) -> Tuple[gr.Dropdown, str]:\n","    load_log = ''\n","    repo = new_model_repo.strip()\n","    # –ø—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –Ω–µ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞\n","    if repo:\n","        repo = repo.split('/')[-2:]\n","        # –ø—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ USER_NAME/REPO_NAME\n","        if len(repo) == 2:\n","            repo = '/'.join(repo).split('?')[0]\n","            # –ø—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –µ—â–µ –Ω–µ—Ç –≤ —Å–ø–∏—Å–∫–µ –≥–æ—Ç–æ–≤—ã—Ö\n","            if repo_exists(repo) and repo not in model_repos:\n","                # –¥–æ–ø –ø—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —Ñ–∞–π–ª—ã GGUF –µ—Å—Ç—å –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –¥–ª—è LLM\n","                # if any([file_name.endswith('.gguf') for file_name in list_repo_files(repo)]):\n","\n","                # –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –≤ —Å–ø–∏—Å–æ–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö\n","                model_repos.insert(0, repo)\n","                load_log += f'–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –º–æ–¥–µ–ª–∏ {repo} —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω\\n'\n","            else:\n","                load_log += '–ù–µ–≤–µ—Ä–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è HF –∏–ª–∏ –º–æ–¥–µ–ª—å —É–∂–µ –µ—Å—Ç—å –≤ —Å–ø–∏—Å–∫–µ\\n'\n","        else:\n","            load_log += '–ù–µ–≤–µ—Ä–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π HF\\n'\n","    else:\n","        load_log += '–ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –≤ –ø–æ–ª–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è HF\\n'\n","    # –≤–µ—Ä–Ω—É—Ç—å –≤—ã–ø–∞–¥–∞—é—â–∏–π —Å–ø–∏—Å–æ–∫ —Å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è–º–∏ HF\n","    model_repo_dropdown = gr.Dropdown(choices=model_repos, value=model_repos[0])\n","    return model_repo_dropdown, load_log\n","\n","\n","# –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π GGUF –∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è HF\n","def get_gguf_model_names(model_repo: str) -> gr.Dropdown:\n","    # –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ –æ –≤—Å–µ—Ö —Ñ–∞–π–ª–∞—Ö –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏\n","    repo_files = list(list_repo_tree(model_repo))\n","    # –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏–æ—Å–æ–∫ –∏–Ω—Ñ–æ j —Ñ–∞–π–ª–∞—á GGUF\n","    repo_files = [file for file in repo_files if file.path.endswith('.gguf')]\n","    # –ø–æ–ª—É—á–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ GGUF –∏ –∏—Ö —Ä–∞–∑–º–µ—Ä\n","    model_paths = [f'{file.path} ({file.size / 1000 ** 3:.2f}G)' for file in repo_files]\n","\n","    # –≤–µ—Ä–Ω—É—Ç—å –≤—ã–ø–∞–¥–∞—é—â–∏–π —Å–ø–∏—Å–∫–æ–∫ —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∏ —Ä–∞–∑–º–µ—Ä–∞–º–∏ —Ñ–∞–π–ª–æ–≤ GGUF\n","    model_paths_dropdown = gr.Dropdown(\n","        choices=model_paths,\n","        value=model_paths[0],\n","        label='–§–∞–π–ª –º–æ–¥–µ–ª–∏ GGUF',\n","        )\n","    return model_paths_dropdown\n","\n","\n","# —É–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∏ –ø–∞–ø–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –º–µ—Å—Ç–∞ –∫—Ä–æ–º–µ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏ gguf_filename\n","def clear_llm_folder(gguf_filename: str) -> None:\n","    if gguf_filename is None:\n","        gr.Info(f'–ù–µ –≤—ã–±—Ä–∞–Ω–æ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–∏ –∫–æ—Ç–æ—Ä—É—é –Ω–µ –Ω—É–∂–Ω–æ —É–¥–∞–ª—è—Ç—å')\n","        return\n","    # –µ—Å–ª–∏ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞ GGUF –µ—Å—Ç—å —Å–∫–æ–±–∫–∞ (–≤ —Å–∫–æ–±–∫–∞—Ö —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ –∫–æ—Ç–æ—Ä—ã–π —Å–∞–º–∏ –¥–æ–±–∞–≤–∏–ª–∏ –≤ get_gguf_model_names())\n","    if '(' in gguf_filename:\n","        # —Ç–æ —É–±—Ä–∞—Ç—å —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ —á—Ç–æ–±—ã —ç—Ç–æ –±—ã–ª–æ –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Ñ–∞–π–ª–∞ GGUF\n","        gguf_filename = gguf_filename.split('(')[0].rstrip()\n","    # —É–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –∫—Ä–æ–º–µ —Ç–µ–∫—É—â–µ–≥–æ\n","    for path in LLM_MODELS_PATH.iterdir():\n","        if path.name == gguf_filename:\n","            continue\n","        if path.is_file():\n","            path.unlink(missing_ok=True)\n","    gr.Info(f'–í—Å–µ —Ñ–∞–π–ª—ã —É–¥–∞–ª–µ–Ω—ã –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {LLM_MODELS_PATH} –∫—Ä–æ–º–µ {gguf_filename}')\n","\n","\n","# —É–¥–∞–ª–µ–Ω–∏–µ –ø–∞–ø–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –º–µ—Å—Ç–∞ –∫—Ä–æ–º–µ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏ model_folder_name\n","def clear_embed_folder(model_repo: str) -> None:\n","    # —á—Ç–æ–±—ã —É–¥–∞–ª–∏—Ç—å –≤—Å–µ –º–æ–¥–µ–ª–∏ –∫—Ä–æ–º–µ —Ç—É–∫—É—â–µ–π, –æ–Ω–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤—ã–±—Ä–∞–Ω–∞\n","    if model_repo is None:\n","        gr.Info(f'–ù–µ –≤—ã–±—Ä–∞–Ω–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∫–æ—Ç–æ—Ä—É—é –Ω–µ –Ω—É–∂–Ω–æ —É–¥–∞–ª—è—Ç—å')\n","        return\n","    # –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π –∏–∑ HF –∏—Ö –ø–∞–ø–∫–∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞—é—Ç—Å—è –∏–∑ USER_NAME/REPO_NAME –≤ USER_NAME_REPO_NAME\n","    model_folder_name = model_repo.replace('/', '_')\n","    # —É–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö –ø–∞–ø–æ–∫ —Å –º–æ–¥–µ–ª—è–º–∏ –∫—Ä–æ–º–µ —Ç–µ–∫—É—â–µ–π\n","    for path in EMBED_MODELS_PATH.iterdir():\n","        if path.name == model_folder_name:\n","            continue\n","        if path.is_dir():\n","            rmtree(path, ignore_errors=True)\n","    gr.Info(f'–í—Å–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —É–¥–∞–ª–µ–Ω—ã –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {EMBED_MODELS_PATH} –∫—Ä–æ–º–µ {model_folder_name}')\n","\n","\n","# # –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤–∏–¥–µ–æ –∏ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç–∏ –≤ Colab\n","# def clear_memory() -> None:\n","#     gc.collect()\n","#     torch.cuda.empty_cache()\n","\n","\n","# ------------------------ YOUTUBE ------------------------\n","\n","# —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å—É–±—Ç–∏—Ç—Ä–æ–≤, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã —Ä—É—á–Ω—ã–µ –∏–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –∏ –ª–æ–≥–∏\n","# –µ—Å–ª–∏ —Å—É–±—Ç–∏—Ç—Ä—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç False –∏ –ª–æ–≥–∏\n","def check_subtitles_available(yt_video_link: str, target_lang: str) -> Tuple[bool, str]:\n","    # –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ ID –≤–∏–¥–µ–æ –∏–∑ –ø–æ–ª–Ω–æ–π —Å—Å—ã–ª–∫–∏ –≤–∏–¥–µ–æ –Ω–∞ YouTube\n","    video_id = yt_video_link.split('watch?v=')[-1].split('&')[0]\n","    # —Å—Ç—Ä–æ–∫–∞ —Å –ª–æ–≥–∞–º–∏\n","    load_log = ''\n","    # —Å—Ç–∞—Ç—É—Å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å—É–±—Ç–∏—Ç—Ä–æ–≤\n","    available = True\n","    try:\n","        # –¥–æ—Å—Ç—É–ø–Ω—ã–µ —è–∑—ã–∫–∏ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –≤–∏–¥–µ–æ\n","        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n","        try:\n","            # –ø–æ–∏—Å–∫ —è–∑—ã–∫–∞ target_lang –≤ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —è–∑—ã–∫–∞—Ö\n","            transcript = transcript_list.find_transcript([target_lang])\n","            # –ø—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —Å—É–±—Ç–∏—Ç—Ä—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏–ª–∏ —Ä—É—á–Ω—ã–µ\n","            if transcript.is_generated:\n","                load_log += f'–ë—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã, —Ä—É—á–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è –≤–∏–¥–µ–æ {yt_video_link}\\n'\n","            else:\n","                load_log += f'–ë—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã —Ä—É—á–Ω—ã–µ —Å—É–±—Ç–∏—Ç—Ä—ã –¥–ª—è –≤–∏–¥–µ–æ {yt_video_link}\\n'\n","        # –µ—Å–ª–∏ —Å—É–±—Ç–∏—Ç—Ä—ã –¥–ª—è –≤–∏–¥–µ–æ –µ—Å—Ç—å –Ω–æ –Ω–µ—Ç —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –Ω–∞ –∂–µ–ª–∞–µ–º–æ–º —è–∑—ã–∫–µ\n","        except NoTranscriptFound:\n","            load_log += f'–Ø–∑—ã–∫ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ {target_lang} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –≤–∏–¥–µ–æ {yt_video_link}\\n'\n","            available = False\n","    # –µ—Å–ª–∏ –Ω–∏–∫–∞–∫–∏—Ö —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –¥–ª—è –≤–∏–¥–µ–æ –Ω–µ—Ç\n","    except TranscriptsDisabled:\n","        load_log += f'–ù–µ—Ç —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –¥–ª—è –≤–∏–¥–µ–æ {yt_video_link}\\n'\n","        available = False\n","    return available, load_log\n","\n","\n","# ------------- –ó–ê–ì–†–£–ó–ö–ê –î–û–ö–£–ú–ï–ù–¢–û–í –î–õ–Ø RAG ------------------------\n","\n","# –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–≤ —Ñ–æ—Ä–º–∞—Ç–µ langchain Documents) –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤\n","def load_documents_from_files(upload_files: List[str]) -> Tuple[List[Document], str]:\n","    # –ª–æ–≥–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —Å–ø–∏—Å–æ–∫ –¥–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n","    load_log = ''\n","    documents = []\n","    # –∏—Ç–µ—Ä–∞—Ü–∏—è –ø–æ –ø—É—Ç—è–º –¥–æ —Ñ–∞–π–ª–æ–≤\n","    for upload_file in upload_files:\n","        # –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–∞\n","        file_extension = f\".{upload_file.split('.')[-1]}\"\n","        # –µ—Å–ª–∏ —Ñ–∞–π–ª —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –µ—Å—Ç—å –≤ —Å–ª–æ–≤–∞—Ä–µ —Å –ª–æ–∞–¥–µ—Ä–∞–º–∏ LOADER_CLASSES\n","        if file_extension in LOADER_CLASSES:\n","            # –∏–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–æ—Ç–≤–µ—Å—Ç–≤—É—é—â–∏–π —Ä–∞—à–∏—Ä–µ–Ω–∏—é –ª–æ–∞–¥–µ—Ä\n","            loader_class = LOADER_CLASSES[file_extension]\n","            loader_kwargs = {}\n","            # –µ—Å–ª–∏ —ç—Ç–æ csv —Ç–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –µ–≥–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å\n","            if file_extension == '.csv':\n","                with open(upload_file) as csvfile:\n","                    delimiter = csv.Sniffer().sniff(csvfile.read(4096)).delimiter\n","                loader_kwargs = {'csv_args': {'delimiter': delimiter}}\n","            try:\n","                # –ø–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Ñ–∞–π–ª–æ–≤\n","                load_documents = loader_class(upload_file, **loader_kwargs).load()\n","                documents.extend(load_documents)\n","            except Exception as ex:\n","                load_log += f'–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ {upload_file}\\n'\n","                load_log += f'–ö–æ–¥ –æ—à–∏–±–∫–∏: {ex}\\n'\n","                continue\n","        else:\n","            load_log += f'–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ {upload_file}\\n'\n","            continue\n","    return documents, load_log\n","\n","\n","# –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–≤ —Ñ–æ—Ä–º–∞—Ç–µ langchain Documents) –∏–∑ WEB —Å—Å—ã–ª–æ–∫\n","def load_documents_from_links(\n","        web_links: str,  # —Å—Å—ã–ª–∫–∏ –Ω–∞ web-—Å–∞–π—Ç—ã –∏–ª–∏ –Ω–∞ –≤–∏–¥–µ–æ YouTube\n","        subtitles_lang: str,  # –∂–µ–ª–∞–µ–º—ã–π —è–∑—ã–∫ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –Ω–∞ YouTube\n","        ) -> Tuple[List[Document], str]:\n","\n","    # –ª–æ–≥–∏ –∑–∞–≥—Ä—É–∑–∫–∏, —Å–ø–∏—Å–æ–∫ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ª–æ–∞–¥–µ—Ä–∞\n","    load_log = ''\n","    documents = []\n","    loader_class_kwargs = {}\n","    # —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫\n","    web_links = [web_link.strip() for web_link in web_links.split('\\n') if web_link.strip()]\n","\n","    # –∏—Ç–µ—Ä–∞—Ü–∏ –ø–æ –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–º —Å—Å—ã–ª–∫–∞–º\n","    for web_link in web_links:\n","        # ----------------- —Å—Å—ã–ª–∫–∞ –Ω–∞ YouTube ---------------------------------\n","        if 'youtube.com' in web_link:\n","            # –ø—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —Å—É–±—Ç–∏—Ç—Ä—ã –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —è–∑—ã–∫–µ subtitles_lang –¥–æ—Å—Ç—É–ø–Ω—ã –≤ –≤–∏–¥–µ–æ web_link\n","            available, log = check_subtitles_available(web_link, subtitles_lang)\n","            load_log += log\n","            # –µ—Å–ª–∏ —Å—É–±—Ç–∏—Ç—Ä—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Å—ã–ª–∫—É\n","            if not available:\n","                continue\n","            # –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è YouTubeLoader —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º —è–∑—ã–∫–∞ —Å—É–±—Ç–∏—Ç—Ä–æ–≤\n","            loader_class = LOADER_CLASSES['youtube'].from_youtube_url\n","            loader_class_kwargs = {'language': subtitles_lang}\n","\n","        # ----------------- —Å—Å—ã–ª–∫–∞ –Ω–µ –Ω–∞ YouTube ------------------------------\n","        else:\n","            # –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è WebBaseLoader\n","            loader_class = LOADER_CLASSES['web']\n","        try:\n","            # –ø—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —Å–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å –ø–æ–º–æ—â—å—é python requests\n","            if requests.get(web_link).status_code != 200:\n","                load_log += f'–°—Å—ã–ª–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è Python requests: {web_link}\\n'\n","                continue\n","            # –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω —Ç–æ –∑–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç —Å —Ç–µ–∫—Å—Ç–æ–º –∏–∑ web —Å—Å—ã–ª–∫–∏\n","            load_documents = loader_class(web_link, **loader_class_kwargs).load()\n","            if len(load_documents) == 0:\n","                load_log += f'–§—Ä–∞–≥–º–µ–Ω—Ç—ã —Ç–µ–∫—Å—Ç–∞ –Ω–µ –±—ã–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –ø–æ —Å—Å—ã–ª–∫–µ: {web_link}\\n'\n","                continue\n","            documents.extend(load_documents)\n","        except MissingSchema:\n","            # –µ—Å–ª–∏ —Å—Å—ã–ª–∫–∞ –Ω–µ–≤–µ—Ä–Ω–∞—è\n","            load_log += f'–ù–µ–≤–µ—Ä–Ω–∞—è —Å—Å—ã–ª–∫–∞: {web_link}\\n'\n","            continue\n","        except Exception as ex:\n","            # –µ—Å–ª–∏ –∫–∞–∫–∞—è —Ç–æ –¥—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞\n","            load_log += f'–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ web –ª–æ–∞–¥–µ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö –ø–æ —Å—Å—ã–ª–∫–µ: {web_link}\\n'\n","            load_log += f'–ö–æ–¥ –æ—à–∏–±–∫–∏: {ex}\\n'\n","            continue\n","    return documents, load_log\n","\n","\n","# –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ –ë–î\n","def load_documents_and_create_db(\n","        upload_files: Optional[List[str]],  # –ø—É—Ç–∏ –¥–æ —Ñ–∞–π–ª–æ–≤, –∑–∞–≥—Ä—É–∂–∞–µ–º—ã–µ —á–µ—Ä–µ–∑ gr.File()\n","        web_links: str,  # —Å—Å—ã–ª–∫–∏ –Ω–∞ web-—Å–∞–π—Ç—ã –∏–ª–∏ –Ω–∞ –≤–∏–¥–µ–æ YouTube\n","        subtitles_lang: str,  # –∂–µ–ª–∞–µ–º—ã–π —è–∑—ã–∫ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –Ω–∞ YouTube\n","        chunk_size: int,  # –∫–æ–ª-–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ –≤–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–µ —Ç–µ–∫—Å—Ç–∞\n","        chunk_overlap: int,  # –¥–ª–∏–Ω–∞ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞\n","        embed_model_dict: EMBED_MODEL_DICT,  # —Å–ª–æ–≤–∞—Ä—å —Å –º–æ–¥–µ–ª—å—é —ç–º–±–µ–¥–∏–Ω–≥–æ–≤\n","        ) -> Tuple[List[Document], Optional[VectorStore], str]:\n","\n","    # –ª–æ–≥–∏ –∑–∞–≥—Ä—É–∑–∫–∏, —Å–ø–∏—Å–æ–∫ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, –ë–î –∏ –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä Gradio\n","    load_log = ''\n","    all_documents = []\n","    db = None\n","    progress = gr.Progress()\n","\n","    # –ø—Ä–æ–≤–µ—Ä–∫–∞ –µ—Å–ª–∏ –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ –æ—Ç—Å—É—Å—Ç–≤—É–µ—Ç –ø–æ –∫–∞–∫–∏–º —Ç–æ –ø—Ä–∏—á–∏–Ω–∞–º\n","    embed_model = embed_model_dict.get('embed_model')\n","    if embed_model is None:\n","        load_log += '–ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞, –ë–î –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞'\n","        return all_documents, db, load_log\n","\n","    # –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã –Ω–∏ –ø—É—Ç–∏ –¥–æ —Ñ–∞–π–ª–æ–≤ –Ω–∏ —Å—Å—ã–ª–∫–∏\n","    if upload_files is None and not web_links:\n","        load_log = '–ù–µ –≤—ã–±—Ä–∞–Ω—ã —Ñ–∞–π–ª—ã –∏–ª–∏ —Å—Å—ã–ª–∫–∏'\n","        return all_documents, db, load_log\n","\n","    # –∑–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–æ–≤\n","    if upload_files is not None:\n","        progress(0.3, desc='–®–∞–≥ 1/2: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–æ–≤')\n","        docs, log = load_documents_from_files(upload_files)\n","        all_documents.extend(docs)\n","        load_log += log\n","\n","    # –∑–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ —Å—Å—ã–ª–∫–∞–º\n","    if web_links:\n","        progress(0.3 if upload_files is None else 0.5, desc='–®–∞–≥ 1/2: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ —Å—Å—ã–ª–∫–∞–º')\n","        docs, log = load_documents_from_links(web_links, subtitles_lang)\n","        all_documents.extend(docs)\n","        load_log += log\n","\n","    # –µ—Å–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞\n","    if len(all_documents) == 0:\n","        load_log += '–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ —Ç–∞–∫ –∫–∞–∫ –Ω–µ –±—ã–ª–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞\\n'\n","        load_log += '–†–µ–∂–∏–º RAG –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω'\n","        return all_documents, db, load_log\n","\n","    load_log += f'–ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(all_documents)}\\n'\n","\n","    # —Ä–∞–∑–¥–µ–ª–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∏ –æ—á–∏—Å—Ç–∫–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤\n","    text_splitter = RecursiveCharacterTextSplitter(\n","        chunk_size=chunk_size,\n","        chunk_overlap=chunk_overlap,\n","        # distance_strategy=DistanceStrategy.COSINE,\n","    )\n","    documents = text_splitter.split_documents(all_documents)\n","    documents = clear_documents(documents)\n","    load_log += f'–î–æ–∫—É–º–µ–Ω—Ç—ã —Ä–∞–∑–¥–µ–ª–µ–Ω—ã, –∫–æ–ª-–≤–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞: {len(documents)}\\n'\n","\n","    # –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î\n","    progress(0.7, desc='–®–∞–≥ 2/2: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î')\n","    db = FAISS.from_documents(documents=documents, embedding=embed_model, )\n","    load_log += '–ë–î –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞, —Ä–µ–∂–∏–º RAG –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω –∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–µ–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω –Ω–∞ –≤–∫–ª–∞–¥–∫–µ Chatbot'\n","    return documents, db, load_log\n","\n","\n","# ------------------ –§–£–ù–ö–¶–ò–ò –ß–ê–¢ –ë–û–¢–ê ------------------------\n","\n","# –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –æ–∫–æ—à–∫–æ —á–∞—Ç –±–æ—Ç–∞\n","def user_message_to_chatbot(user_message: str, chatbot: CHAT_HISTORY) -> Tuple[str, CHAT_HISTORY]:\n","    # if user_message:\n","    # chatbot.append([user_message, None])  # gradio < 5\n","    chatbot.append({'role': 'user', 'metadata': {'title': None}, 'content': user_message})\n","    return '', chatbot\n","\n","\n","# —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º—Ç–∞ —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –µ—Å–ª–∏ –ë–î –¥–æ—Å—Ç—É–ø–Ω–∞ –∏ —Ä–µ–∂–∏–º RAG –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω\n","# –∏–Ω–∞—á–µ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º—Ç–∞ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ - –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –æ–±—â–µ–Ω–∏—è —Å –±–æ—Ç–æ–º\n","def update_user_message_with_context(\n","        chatbot: CHAT_HISTORY,  # –æ–±—ä–µ–∫—Ç —á–∞—Ç–±–æ—Ç–∞ - —Å–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤ —Ä–µ–ø–ª–∏–∫ —é–∑–µ—Ä–∞ –∏ –±–æ—Ç–∞\n","        rag_mode: bool,  # —Ä–µ–∂–∏–º RAG - –≤–∫–ª—é—á–µ–Ω –∏–ª–∏ –æ—Ç–∫–ª—é—á–µ–Ω\n","        db: VectorStore,  # –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î\n","        k: Union[int, str],  # –∫–æ–ª-–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n","        score_threshold: float,  # –ø–æ—Ä–æ–≥–æ –ø–æ –∫–æ—Ç–æ—Ä–æ–º—É –∏—â—É—Ç—Å—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n","        ) -> Tuple[str, CHAT_HISTORY]:\n","\n","    # —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n","    user_message = chatbot[-1]['content']\n","    # –µ—Å–ª–∏ RAG –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø—Ä–æ–º—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –±—É–¥–µ—Ç –ø—É—Å—Ç–æ–π\n","    user_message_with_context = ''\n","\n","    # –µ—Å–ª–∏ –ë–î –≥–æ—Ç–æ–≤–∞ –∏ –≤–∫–ª—é—á–µ–Ω —Ä–µ–∂–∏–º RAG —Ç–æ –∏—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫–∏ –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ –ø—Ä–æ–º—Ç\n","    if db is not None and rag_mode and user_message.strip():\n","        # –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã, —Å–∫–æ—Ä –∫–æ—Ç–æ—Ä—ã—Ö –±–æ–ª—å—à–µ score_threshold\n","        if k == 'all':\n","            k = len(db.docstore._dict)\n","        # –ø–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞\n","        docs_and_distances = db.similarity_search_with_relevance_scores(\n","            user_message,\n","            k=k,\n","            score_threshold=score_threshold,\n","            )\n","        # –µ—Å–ª–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–∞–π–¥–µ–Ω—ã\n","        if len(docs_and_distances) > 0:\n","            # —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞\n","            retriever_context = '\\n\\n'.join([doc[0].page_content for doc in docs_and_distances])\n","            # –æ–±–æ–≥–∞—â–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è —é–∑–µ—Ä–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º\n","            user_message_with_context = CONTEXT_TEMPLATE.format(\n","                user_message=user_message,\n","                context=retriever_context,\n","                )\n","    return user_message_with_context\n","\n","\n","# –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –º–æ–¥–µ–ª—å—é\n","def get_llm_response(\n","        chatbot: CHAT_HISTORY,  # —Å–ø–∏—Å–æ–∫ –ø–µ—Ä–µ–ø–∏—Å–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –±–æ—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è –≤ –æ–∫–æ—à–∫–µ —á–∞—Ç-–±–æ—Ç–∞\n","        llm_model_dict: LLM_MODEL_DICT,  # —Å–ª–æ–≤–∞—Ä—å —Å –º–æ–¥–µ–ª—å llama-cpp-python\n","        user_message_with_context: str,  # —Ç–µ–∫—É—â–µ–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ–±–æ–≥–∞—â–µ–Ω–Ω–æ–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º\n","        rag_mode: bool,  # —Ä–µ–∂–∏–º RAG - –≤–∫–ª—é—á–µ–Ω –∏–ª–∏ –æ—Ç–∫–ª—é—á–µ–Ω\n","        system_prompt: str,  # —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç\n","        support_system_role: bool,  # –ø–æ–¥–¥–µ—Ä–∂–∏—ã–≤–∞–µ—Ç –ª–∏ –º–æ–¥–µ–ª—å —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç\n","        history_len: int,  # –∫–æ–ª-–≤–æ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∫–æ—Ç–æ—Ä—ã–µ —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –≤ –∏—Å—Ç–æ—Ä–∏–∏\n","        do_sample: bool,  # –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ —Å–ª—É—á–∞–π–Ω–æ–µ —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª—å—é\n","        *generate_args,  # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏\n","        ) -> CHAT_HISTORY:\n","\n","    # –ø–æ–ª—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n","    llm_model = llm_model_dict.get('llm_model')\n","    if llm_model is None:\n","        gr.Info('Model not initialized')\n","        yield chatbot\n","        return\n","\n","    # –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞\n","    gen_kwargs = dict(zip(GENERATE_KWARGS.keys(), generate_args))\n","    gen_kwargs['top_k'] = int(gen_kwargs['top_k'])\n","    # –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è –µ—Å–ª–∏ do_sample=False\n","    if not do_sample:\n","        gen_kwargs['top_p'] = 0.0\n","        gen_kwargs['top_k'] = 1\n","        gen_kwargs['repeat_penalty'] = 1.0\n","\n","    # –ø–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n","    user_message = chatbot[-1]['content']\n","    # –µ—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø—É—Å—Ç–æ–µ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—É—â–µ–µ –æ–∫–Ω–æ —á–∞—Ç –±–æ—Ç–∞\n","    if not user_message.strip():\n","        # –¥–ª—è —ç—Ç–æ–≥–æ —Å–Ω–∞—á–∞–ª–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–µ—Ä–µ–ø–∏—Å–∫—É –¥–æ —Ç–µ–∫—É—â–µ–≥–æ –ø—É—Å—Ç–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è —é–∑–µ—Ä–∞\n","        yield chatbot[:-1]\n","        # –∑–∞—Ç–µ–º –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ñ—É–Ω–∫—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —á–µ—Ä–µ–∑ return None\n","        return\n","\n","    # –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω —Ä–µ–∂–∏–º RAG\n","    if rag_mode:\n","         # –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –Ω–µ –ø—É—Å—Ç–æ–π —Ç–æ —ç—Ç–æ –∏ –±—É–¥–µ—Ç –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n","        if user_message_with_context:\n","            user_message = user_message_with_context\n","        # –µ—Å–ª–∏ –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø—Ä–æ–º—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏ —Ä–µ–∂–∏–º RAG –∞–∫—Ç–∏–≤–µ–Ω —Ç–æ –≤–µ—Ä–Ω—É—Ç—å —Ç–µ–∫—É—â–µ–µ –æ–∫–Ω–æ –±–æ—Ç–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π\n","        else:\n","            gr.Info((\n","                f'–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—É –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤ —Ä–µ–∂–∏–º–µ RAG –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞.\\n'\n","                f'–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–º–µ–Ω—å—à–∏—Ç—å searh_score_threshold –∏–ª–∏ –æ—Ç–∫–ª—é—á–∏—Ç–µ —Ä–µ–∂–∏–º RAG –¥–ª—è –æ–±—ã—á–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏'\n","                ))\n","            yield chatbot[:-1]\n","            return\n","\n","    # —Å–ø–∏—Å–æ–∫ —Å –ø–µ—Ä–µ–ø–∏—Å–∫–∞–º–∏ —é–∑–µ—Ä–∞ –∏ –±–æ—Ç–∞ –¥–ª—è –ø–æ–¥–∞—á–∏ –≤ –º–æ–¥–µ–ª—å\n","    messages = []\n","\n","    # –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º—Ç–∞ –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –º–æ–¥–µ–ª—å—é\n","    if support_system_role and system_prompt:\n","        messages.append({'role': 'system', 'metadata': {'title': None}, 'content': system_prompt})\n","\n","    # –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –ø–µ—Ä–µ–ø–∏—Å–∫–∏ –≤ –ø—Ä–æ–º—Ç (–ø–æ 2 —Å–æ–æ–±—â–µ–Ω–∏—è - —é–∑–µ—Ä–∞ –∏ –±–æ—Ç–∞)\n","    if history_len != 0:\n","        messages.extend(chatbot[:-1][-(history_len*2):])\n","\n","    # –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n","    messages.append({'role': 'user', 'metadata': {'title': None}, 'content': user_message})\n","\n","    # —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª—å—é —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º –ø—Ä–æ–º—Ç–∞\n","    stream_response = llm_model.create_chat_completion(\n","        messages=messages,\n","        stream=True,\n","        **gen_kwargs,\n","        )\n","\n","    # –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª—å—é, –Ω–∞–ø—Ä–∏–º–µ—Ä –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n","    try:\n","        # –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –±—É–¥–µ–º –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä–æ–≤–∞—Ç—å —Å —Ç–æ–∫–µ–Ω–∞–º–∏ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏\n","        chatbot.append({'role': 'assistant', 'metadata': {'title': None}, 'content': ''})\n","        # –∏—Ç–µ—Ä–∞—Ü–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ –≤ —Ü–∏–∫–ª–µ\n","        for chunk in stream_response:\n","            token = chunk['choices'][0]['delta'].get('content')\n","            if token is not None:\n","                chatbot[-1]['content'] += token\n","                yield chatbot\n","    except Exception as ex:\n","        gr.Info(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞, –∫–æ–¥ –æ—à–∏–±–∫–∏: {ex}')\n","        yield chatbot[:-1]\n","        return"],"metadata":{"id":"I8LD34gFKxEv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## –ö–æ–Ω—Ñ–∏–≥"],"metadata":{"id":"JR8cnRdHn8ga"}},{"cell_type":"markdown","source":["–ú–æ–¥—É–ª—å `congig.py`"],"metadata":{"id":"IV7_exV_Ugfd"}},{"cell_type":"code","source":["from pathlib import Path\n","\n","# document loaders\n","from langchain_community.document_loaders import (\n","    CSVLoader,\n","    PDFMinerLoader,\n","    PyPDFLoader,\n","    TextLoader,\n","    UnstructuredHTMLLoader,\n","    UnstructuredMarkdownLoader,\n","    UnstructuredPowerPointLoader,\n","    UnstructuredWordDocumentLoader,\n","    WebBaseLoader,\n","    YoutubeLoader,\n","    DirectoryLoader,\n",")\n","\n","\n","# –∫–ª–∞—Å—Å—ã langchain –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤\n","LOADER_CLASSES = {\n","    '.csv': CSVLoader,\n","    '.doc': UnstructuredWordDocumentLoader,\n","    '.docx': UnstructuredWordDocumentLoader,\n","    '.html': UnstructuredHTMLLoader,\n","    '.md': UnstructuredMarkdownLoader,\n","    '.pdf': PDFMinerLoader,\n","    '.ppt': UnstructuredPowerPointLoader,\n","    '.pptx': UnstructuredPowerPointLoader,\n","    '.txt': TextLoader,\n","    'web': WebBaseLoader,\n","    'directory': DirectoryLoader,\n","    'youtube': YoutubeLoader,\n","}\n","\n","# –ø—Ä–∏–º–µ—Ä –≤–∏–¥–µ–æ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å—É–±—Ç–∏—Ç—Ä–∞–º–∏\n","# https://www.youtube.com/watch?v=CFVABT8wtl4\n","# –ø—Ä–∏–º–µ—Ä –≤–∏–¥–µ–æ —Å –æ–±—ã—á–Ω—ã–º–∏ —Å—É–±—Ç–∏—Ç—Ä–∞–º–∏\n","# https://www.youtube.com/watch?v=EEGk7gHoKfY\n","\n","# —è–∑—ã–∫–∏ –¥–ª—è —Å—É–±—Ç–∏—Ç—Ä–æ–≤ YouTube\n","SUBTITLES_LANGUAGES = ['ru', 'en']\n","\n","# —à–∞–±–ª–æ–Ω –ø—Ä–æ–º—Ç–∞ –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n","CONTEXT_TEMPLATE = '''–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.\n","\n","–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n","{context}\n","\n","–í–æ–ø—Ä–æ—Å:\n","{user_message}\n","\n","–û—Ç–≤–µ—Ç:'''\n","\n","# —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –∫–æ–Ω—Ñ–∏–≥–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞\n","GENERATE_KWARGS = dict(\n","    temperature=0.2,  # —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Å–æ—Ñ—Ç–º–∞–∫—Å–∞\n","    top_p=0.95,  # —Å—É–º–º–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Ç–æ–∫–µ–Ω–æ–≤ –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –Ω—É–∂–Ω–æ –≤—ã–±–∏—Ä–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω\n","    top_k=40,  # –∏–∑ —Å–∫–æ–ª—å–∫–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤—ã–±–∏—Ä–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω\n","    repeat_penalty=1.0,  # —à—Ç—Ä–∞—Ñ –º–æ–¥–µ–ª–∏ –∑–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è\n","    )\n","\n","# –ø—É—Ç–∏ –¥–æ –º–æ–¥–µ–ª–µ–π LLM –∏ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤\n","LLM_MODELS_PATH = Path('models')\n","EMBED_MODELS_PATH = Path('embed_models')\n","LLM_MODELS_PATH.mkdir(exist_ok=True)\n","EMBED_MODELS_PATH.mkdir(exist_ok=True)\n","\n","# –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è LLM –º–æ–¥–µ–ª–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ GGUF\n","LLM_MODEL_REPOS = [\n","    # https://huggingface.co/bartowski/gemma-2-2b-it-GGUF\n","    'bartowski/gemma-2-2b-it-GGUF',\n","    # https://huggingface.co/bartowski/Qwen2.5-3B-Instruct-GGUF\n","    'bartowski/Qwen2.5-3B-Instruct-GGUF',\n","    # https://huggingface.co/bartowski/Qwen2.5-1.5B-Instruct-GGUF\n","    'bartowski/Qwen2.5-1.5B-Instruct-GGUF',\n","    # https://huggingface.co/bartowski/openchat-3.6-8b-20240522-GGUF\n","    'bartowski/openchat-3.6-8b-20240522-GGUF',\n","    # https://huggingface.co/bartowski/Mistral-7B-Instruct-v0.3-GGUF\n","    'bartowski/Mistral-7B-Instruct-v0.3-GGUF',\n","    # https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF\n","    'bartowski/Llama-3.2-3B-Instruct-GGUF',\n","]\n","\n","# –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤\n","EMBED_MODEL_REPOS = [\n","    # https://huggingface.co/sergeyzh/rubert-tiny-turbo  # 117 MB\n","    'sergeyzh/rubert-tiny-turbo',\n","    # https://huggingface.co/cointegrated/rubert-tiny2  # 118 MB\n","    'cointegrated/rubert-tiny2',\n","    # https://huggingface.co/cointegrated/LaBSE-en-ru  # 516 MB\n","    'cointegrated/LaBSE-en-ru',\n","    # https://huggingface.co/sergeyzh/LaBSE-ru-turbo  # 513 MB\n","    'sergeyzh/LaBSE-ru-turbo',\n","    # https://huggingface.co/intfloat/multilingual-e5-large  # 2.24 GB\n","    'intfloat/multilingual-e5-large',\n","    # https://huggingface.co/intfloat/multilingual-e5-base  # 1.11 GB\n","    'intfloat/multilingual-e5-base',\n","    # https://huggingface.co/intfloat/multilingual-e5-small  # 471 MB\n","    'intfloat/multilingual-e5-small',\n","    # https://huggingface.co/intfloat/multilingual-e5-large-instruct  # 1.12 GB\n","    'intfloat/multilingual-e5-large-instruct',\n","    # https://huggingface.co/sentence-transformers/all-mpnet-base-v2  # 438 MB\n","    'sentence-transformers/all-mpnet-base-v2',\n","    # https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2  # 1.11 GB\n","    'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n","    # https://huggingface.co/ai-forever?search_models=ruElectra  # 356 MB\n","    'ai-forever/ruElectra-medium',\n","    # https://huggingface.co/ai-forever/sbert_large_nlu_ru  # 1.71 GB\n","    'ai-forever/sbert_large_nlu_ru',\n","]"],"metadata":{"id":"XI7A17vzn5Ng"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ"],"metadata":{"id":"vbODSV_KKlv4"}},{"cell_type":"markdown","source":["–ú–æ–¥—É–ª—å `app.py`"],"metadata":{"id":"mQzRE8CkUoOf"}},{"cell_type":"markdown","source":["–ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"],"metadata":{"id":"orsFLHsFe7Lt"}},{"cell_type":"code","source":["from typing import List, Optional\n","\n","import gradio as gr\n","from langchain_core.vectorstores import VectorStore\n","\n","# —Ä–∞—Å—Å–∫–æ–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–º–ø–æ—Ä—Ç—ã –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –Ω–µ –≤ Colab\n","\n","# from config import (\n","#     LLM_MODEL_REPOS,\n","#     EMBED_MODEL_REPOS,\n","#     SUBTITLES_LANGUAGES,\n","#     GENERATE_KWARGS,\n","# )\n","\n","# from utils import (\n","#     load_llm_model,\n","#     load_embed_model,\n","#     load_documents_and_create_db,\n","#     user_message_to_chatbot,\n","#     update_user_message_with_context,\n","#     get_llm_response,\n","#     get_gguf_model_names,\n","#     add_new_model_repo,\n","#     clear_llm_folder,\n","#     clear_embed_folder,\n","#     get_memory_usage,\n","# )\n","\n","\n","# =============== –§–£–ù–ö–¶–ò–ò –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–ò –ö–û–ú–ü–û–ù–ï–ù–¢ –ò–ù–¢–ï–†–§–ï–ô–°–ê ============\n","\n","# —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ RAG\n","def get_rag_settings(rag_mode: bool, render: bool = True):\n","    # –∫–æ–ª-–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –ë–î\n","    k = gr.Radio(\n","        choices=[1, 2, 3, 4, 5, 'all'],\n","        value=2,\n","        label='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞',\n","        visible=rag_mode,\n","        render=render,\n","        )\n","    # –ø–æ—Ä–æ–≥ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞ –æ—Ç 0 –¥–æ 1 (—á–µ–º –Ω–∏–∂–µ —Ç–µ–º –±–æ–ª—å—à–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –±—É–¥–µ—Ç –Ω–∞–π–¥–µ–Ω–æ)\n","    score_threshold = gr.Slider(\n","        minimum=0,\n","        maximum=1,\n","        value=0.5,\n","        step=0.05,\n","        label='relevance_scores_threshold',\n","        visible=rag_mode,\n","        render=render,\n","        )\n","    return k, score_threshold\n","\n","\n","# –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–æ–º—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º\n","def get_user_message_with_context(text: str, rag_mode: bool) -> gr.component:\n","    # –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–ª-–≤–∞ —Å—Ç—Ä–æ–∫ –≤ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º–æ–º –æ–∫–Ω–µ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞\n","    num_lines = len(text.split('\\n'))\n","    max_lines = 10\n","    num_lines = max_lines if num_lines > max_lines else num_lines\n","    return gr.Textbox(\n","        text,\n","        visible=rag_mode,\n","        interactive=False,\n","        label='User Message With Context',\n","        lines=num_lines,\n","        )\n","\n","\n","# –ø–æ–ª—É—á–µ–Ω–∏–µ –æ–∫–æ—à–∫–∞ –¥–ª—è —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º—Ç–∞. –µ—Å–ª–∏ interactive=True —Ç–æ –º–æ–∂–Ω–æ –≤–≤–æ–¥–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç\n","# –ø—Ä–∏–º–µ—Ä—ã —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –ø—Ä–æ–º—Ç–æ–≤:\n","# –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫—Ä–∞—Ç–∫–æ, –µ—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç - –≥–æ–≤–æ—Ä–∏ \"–Ω–µ –∑–Ω–∞—é\".\n","# –ï—Å–ª–∏ –≤ –≤–æ–ø—Ä–æ—Å–µ –µ—Å—Ç—å —Ö–æ—Ç—å –º–∞–ª–µ–π—à–∏–π –Ω–∞–º–µ–∫ –Ω–∞ –ø–æ–ª–∏—Ç–∏–∫—É, –Ω–∞—Å–∏–ª–∏–µ, —Ä—É–≥–∞—Ç–µ–ª—å—Å—Ç–≤–∞, –æ—Ç–≤–µ—Ç—å —Ç–∞–∫: \"–ù–∞ —ç—Ç—É —Ç–µ–º—É —è –Ω–µ –º–æ–≥—É –≥–æ–≤–æ—Ä–∏—Ç—å\".\n","def get_system_prompt_component(interactive: bool) -> gr.Textbox:\n","    value = '' if interactive else 'System prompt is not supported by this model'\n","    return gr.Textbox(value=value, label='System prompt', interactive=interactive)\n","\n","\n","# –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–Ω—Ñ–∏–≥–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞\n","def get_generate_args(do_sample: bool) -> List[gr.component]:\n","    # –µ—Å–ª–∏ do_sample –≤–∫–ª—é—á–µ–Ω (—ç–ª–µ–º–µ–Ω—Ç gr.Checkbox() –∞–∫—Ç–∏–≤–µ–Ω) —Ç–æ –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å —Å–ª–∞–π–¥–µ—Ä–∞ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n","    generate_args = [\n","        gr.Slider(minimum=0.1, maximum=3, value=GENERATE_KWARGS['temperature'], step=0.1, label='temperature', visible=do_sample),\n","        gr.Slider(minimum=0.1, maximum=1, value=GENERATE_KWARGS['top_p'], step=0.01, label='top_p', visible=do_sample),\n","        gr.Slider(minimum=1, maximum=50, value=GENERATE_KWARGS['top_k'], step=1, label='top_k', visible=do_sample),\n","        gr.Slider(minimum=1, maximum=5, value=GENERATE_KWARGS['repeat_penalty'], step=0.1, label='repeat_penalty', visible=do_sample),\n","    ]\n","    return generate_args\n","\n","\n","# –∫–æ–º–ø–æ—Ä–Ω–µ–Ω—Ç –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è —Ä–µ–∂–∏–º–∞ RAG\n","def get_rag_mode_component(db: Optional[VectorStore]) -> gr.Checkbox:\n","    value = visible = db is not None\n","    return gr.Checkbox(value=value, label='RAG Mode', scale=1, visible=visible)\n","\n","\n","# ================ –ó–ê–ì–†–£–ó–ö–ê –ò –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ú–û–î–ï–õ–ï–ô ========================\n","\n","# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤–∞—Ä—è —Å LLM –º–æ–¥–µ–ª—å—é, —Ñ–ª–∞–≥–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º—Ç–∞ –º–æ–¥–µ–ª—å—é –∏ –ª–æ–≥–æ–≤ –∑–∞–≥—Ä—É–∑–∫–∏\n","start_llm_model, start_support_system_role, load_log = load_llm_model(LLM_MODEL_REPOS[0], 'gemma-2-2b-it-Q8_0.gguf')\n","# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤–∞—Ä—è —Å –º–æ–¥–µ–ª—å—é —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ –∏ –ª–æ–≥–æ–≤ –∑–∞–≥—Ä—É–∑–∫–∏\n","start_embed_model, load_log = load_embed_model(EMBED_MODEL_REPOS[0])\n","\n","\n","# ====================== –ò–ù–¢–ï–†–§–ï–ô–° –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø ============================\n","\n","# —Ç–µ–º–∞ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è\n","# theme = gr.themes.Monochrome()\n","theme = gr.themes.Base(primary_hue='green', secondary_hue='yellow', neutral_hue='zinc').set(\n","    loader_color='rgb(0, 255, 0)',\n","    slider_color='rgb(0, 200, 0)',\n","    body_text_color_dark='rgb(0, 200, 0)',\n","    button_secondary_background_fill_dark='green',\n",")\n","# –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —à–∏—Ä–∏–Ω—ã –æ–∫–Ω–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ CSS\n","css = '''.gradio-container {width: 60% !important}'''\n","\n","# –Ω–∞—á–∞–ª–æ –æ–ø–∏—Å–∞–Ω–∏—è –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è\n","with gr.Blocks(theme=theme, css=css) as interface:\n","\n","    # ==================== –°–û–°–¢–û–Ø–ù–ò–Ø ===============================\n","\n","    # –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Ç–µ–∫—Å—Ç–∞ (—Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ langchain Document)\n","    documents = gr.State([])\n","    # –ë–î\n","    db = gr.State(None)\n","    # –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø—Ä–æ–º—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n","    user_message_with_context = gr.State('')\n","    # —Ñ–ª–∞–≥ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º—Ç–∞ –º–æ–¥–µ–ª—å—é\n","    support_system_role = gr.State(start_support_system_role)\n","\n","    # —Å–ø–∏—Å–∫–∏ –≥–æ—Ç–æ–≤—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –º–æ–¥–µ–ª–µ–π HF\n","    llm_model_repos = gr.State(LLM_MODEL_REPOS)\n","    embed_model_repos = gr.State(EMBED_MODEL_REPOS)\n","\n","    # —Å–ª–æ–≤–∞—Ä–∏ —Å –º–æ–¥–µ–ª—è–º–∏ LLM –∏ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤\n","    llm_model = gr.State(start_llm_model)\n","    embed_model = gr.State(start_embed_model)\n","\n","\n","\n","    # ==================== –°–¢–†–ê–ù–ò–¶–ê –ë–û–¢–ê =================================\n","\n","    with gr.Tab(label='Chatbot'):\n","        with gr.Row():\n","            with gr.Column(scale=3):\n","                # –æ–∫–æ—à–∫–æ —á–∞—Ç –±–æ—Ç–∞\n","                chatbot = gr.Chatbot(\n","                    type='messages',  # new in gradio 5+\n","                    show_copy_button=True,\n","                    bubble_full_width=False,\n","                    height=480,\n","                )\n","                # —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n","                user_message = gr.Textbox(label='User')\n","\n","                with gr.Row():\n","                    # –∫–Ω–æ–ø–∫–∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ, —Å—Ç–æ–ø –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ —É–¥–∞–ª–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞\n","                    user_message_btn = gr.Button('–û—Ç–ø—Ä–∞–≤–∏—Ç—å')\n","                    stop_btn = gr.Button('–°—Ç–æ–ø')\n","                    clear_btn = gr.Button('–û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç')\n","\n","            # ------------------ –ü–ê–†–ê–ú–ï–¢–†–´ –ì–ï–ù–ï–†–ê–¶–ò–ò -------------------------\n","\n","            with gr.Column(scale=1, min_width=80):\n","                with gr.Group():\n","                    # –¥–ª–∏–Ω–∞ –∏—Å—Ç–æ—Ä–∏–∏ –∫–æ—Ç–æ—Ä—É—é –±—É–¥–µ—Ç —É—á–∏—Ç—ã–≤–∞—Ç—å –º–æ–¥–µ–ª—å\n","                    gr.Markdown('–†–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏')\n","                    history_len = gr.Slider(\n","                        minimum=0,\n","                        maximum=5,\n","                        value=0,\n","                        step=1,\n","                        info='–ö–æ–ª-–≤–æ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–µ–π, —É—á–∏—Ç—ã–≤–∞–µ–º—ã—Ö –≤ –∏—Å—Ç–æ—Ä–∏–∏',\n","                        label='history len',\n","                        show_label=False,\n","                        )\n","\n","                    with gr.Group():\n","                        gr.Markdown('–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏')\n","                        # –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –º–æ–¥–µ–ª—å—é\n","                        do_sample = gr.Checkbox(\n","                            value=False,\n","                            label='do_sample',\n","                            info='–ê–∫—Ç–∏–≤–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è',\n","                            )\n","                        # –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è\n","                        generate_args = get_generate_args(do_sample.value)\n","                        do_sample.change(\n","                            fn=get_generate_args,\n","                            inputs=do_sample,\n","                            outputs=generate_args,\n","                            show_progress=False,\n","                            )\n","\n","        # –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å –≤–∫–ª—é—á–∏—Ç—å –∏–ª–∏ –≤—ã–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º RAG (–¥–∞–∂–µ –µ—Å–ª–∏ –ë–î –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ RAG –º–æ–∂–Ω–æ –æ—Ç–∫–ª—é—á–∏—Ç—å)\n","        rag_mode = get_rag_mode_component(db=db.value)\n","        # —á–∏—Å–ª–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–≥–∞–º–µ–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä score_threshold\n","        k, score_threshold = get_rag_settings(rag_mode=rag_mode.value, render=False)\n","        # –Ω–∞–∂–∞—Ç–∏–µ –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—è —Ä–µ–∂–∏–º–∞ RAG\n","        rag_mode.change(\n","            fn=get_rag_settings,\n","            inputs=[rag_mode],\n","            outputs=[k, score_threshold],\n","            )\n","\n","        # –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å –≤ —ç—Ç–æ–º –º–µ—Å—Ç–µ —ç–∫—Ä–∞–Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã k –∏ score_threshold\n","        with gr.Row():\n","            k.render()\n","            score_threshold.render()\n","\n","        # ---------------- –°–ò–°–¢–ï–ú–ù–´–ô –ü–†–û–ú–¢ –ò –°–û–û–ë–©–ï–ù–ò–ï –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø ---------\n","\n","        with gr.Accordion('–ü—Ä–æ–º—Ç', open=True):\n","            # –æ–∫–æ—à–∫–æ –¥–ª—è —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º—Ç–∞\n","            system_prompt = get_system_prompt_component(interactive=support_system_role.value)\n","            # –∏—Ç–æ–≥–æ–≤—ã—ã–π –ø—Ä–æ–º—Ç –∫–æ—Ç–æ—Ä—ã–π –ø–æ–¥–∞–µ—Ç—Å—è –≤ –º–æ–¥–µ–ª—å\n","            user_message_with_context = get_user_message_with_context(text='', rag_mode=rag_mode.value)\n","\n","        # ------------------ –ö–ù–û–ü–ö–ò –û–¢–ü–†–ê–í–ò–¢–¨ –û–ß–ò–°–¢–ò–¢–¨ –ò –°–¢–û–ü ------------\n","\n","        # –Ω–∞–∂–∞—Ç–∏–µ Enter –∏ –∫–Ω–æ–ø–∫–∞ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å\n","        generate_event = gr.on(\n","            triggers=[user_message.submit, user_message_btn.click],\n","            fn=user_message_to_chatbot,\n","            inputs=[user_message, chatbot],\n","            outputs=[user_message, chatbot],\n","            queue=False,\n","        ).then(\n","            fn=update_user_message_with_context,\n","            inputs=[chatbot, rag_mode, db, k, score_threshold],\n","            outputs=[user_message_with_context],\n","        ).then(\n","            fn=get_user_message_with_context,\n","            inputs=[user_message_with_context, rag_mode],\n","            outputs=[user_message_with_context],\n","        ).then(\n","            fn=get_llm_response,\n","            inputs=[chatbot, llm_model, user_message_with_context, rag_mode, system_prompt,\n","                    support_system_role, history_len, do_sample, *generate_args],\n","            outputs=[chatbot],\n","        )\n","\n","        # –∫–Ω–æ–ø–∫–∞ –°—Ç–æ–ø\n","        stop_btn.click(\n","            fn=None,\n","            inputs=None,\n","            outputs=None,\n","            cancels=generate_event,\n","            queue=False,\n","        )\n","\n","        # –∫–Ω–æ–ø–∫–∞ –û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç\n","        clear_btn.click(\n","            fn=lambda: (None, ''),\n","            inputs=None,\n","            outputs=[chatbot, user_message_with_context],\n","            queue=False,\n","            )\n","\n","\n","\n","    # ===================== –°–¢–†–ê–ù–ò–¶–ê –ó–ê–ì–†–£–ó–ö–ò –§–ê–ô–õ–û–í =========================\n","\n","    with gr.Tab(label='Load documents'):\n","        with gr.Row(variant='compact'):\n","            # –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ –∏ —Å—Å—ã–ª–æ–∫\n","            upload_files = gr.File(file_count='multiple', label='–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤')\n","            web_links = gr.Textbox(lines=6, label='–°—Å—ã–ª–∫–∏ –Ω–∞ Web —Å–∞–π—Ç—ã –∏–ª–∏ –Æ—Ç—É–±')\n","\n","        with gr.Row(variant='compact'):\n","            # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Ä–µ–∑–∫–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã\n","            chunk_size = gr.Slider(50, 2000, value=500, step=50, label='–î–ª–∏–Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤')\n","            chunk_overlap = gr.Slider(0, 200, value=20, step=10, label='–î–ª–∏–Ω–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤')\n","\n","            # —è–∑—ã–∫ —Å—É–±—Ç–∏—Ç—Ä–æ–≤\n","            subtitles_lang = gr.Radio(\n","                SUBTITLES_LANGUAGES,\n","                value=SUBTITLES_LANGUAGES[0],\n","                label='–Ø–∑—ã–∫ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ YouTube',\n","                )\n","\n","        # –∫–Ω–æ–ø–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ë–î\n","        load_documents_btn = gr.Button(value='–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ë–î')\n","        # —Å—Ç–∞—Ç—É—Å –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ë–î\n","        load_docs_log = gr.Textbox(label='–°—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤', interactive=False)\n","\n","        # –≥–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫–æ–≤ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞\n","        load_documents_btn.click(\n","            fn=load_documents_and_create_db,\n","            inputs=[upload_files, web_links, subtitles_lang, chunk_size, chunk_overlap, embed_model],\n","            outputs=[documents, db, load_docs_log],\n","        ).success(\n","            fn=get_rag_mode_component,\n","            inputs=[db],\n","            outputs=[rag_mode],\n","        )\n","\n","        gr.HTML(\"\"\"<h3 style='text-align: center'>\n","        <a href=\"https://github.com/sergey21000/chatbot-rag\" target='_blank'>GitHub Repository</a></h3>\n","        \"\"\")\n","\n","\n","    # ================= –°–¢–†–ê–ù–ò–¶–ê –ü–†–û–°–ú–û–¢–†–ê –í–°–ï–• –î–û–ö–£–ú–ï–ù–¢–û–í =================\n","\n","    with gr.Tab(label='View documents'):\n","        # –∫–Ω–æ–ø–∫–∞ –∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞\n","        view_documents_btn = gr.Button(value='–û—Ç–æ–±—Ä–∞–∑–∏—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã')\n","        view_documents_textbox = gr.Textbox(\n","            lines=1,\n","            placeholder='–î–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–∞ –≤–∫–ª–∞–¥–∫–µ Load documents',\n","            label='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã',\n","            )\n","        sep = '=' * 20\n","        # –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞ –µ—Å–ª–∏ –æ–Ω–∏ –≥–æ—Ç–æ–≤—ã\n","        view_documents_btn.click(\n","            lambda documents: f'\\n{sep}\\n\\n'.join([doc.page_content for doc in documents]),\n","            inputs=[documents],\n","            outputs=[view_documents_textbox],\n","        )\n","\n","\n","\n","    # ============== –°–¢–†–ê–ù–ò–¶–ê –ó–ê–ì–†–£–ó–ö–ò GGUF –ú–û–î–ï–õ–ï–ô =====================\n","\n","    with gr.Tab('Load LLM model'):\n","        # –æ–∫–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤–æ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è —Å HF\n","        new_llm_model_repo = gr.Textbox(\n","            value='',\n","            label='–î–æ–±–∞–≤–∏—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π',\n","            placeholder='–°—Å—ã–ª–∫–∞ –Ω–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π HF –º–æ–¥–µ–ª–µ–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ GGUF',\n","            )\n","        new_llm_model_repo_btn = gr.Button('–î–æ–±–∞–≤–∏—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π')\n","\n","        # –≤—ã–±–æ—Ä —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è HF –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö\n","        curr_llm_model_repo = gr.Dropdown(\n","            choices=LLM_MODEL_REPOS,\n","            value=None,\n","            label='–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –º–æ–¥–µ–ª–∏ HF',\n","            )\n","        # –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ GGUF –∏–∑ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è\n","        curr_llm_model_path = gr.Dropdown(\n","            choices=[],\n","            value=None,\n","            label='–§–∞–π–ª –º–æ–¥–µ–ª–∏ GGUF',\n","            )\n","        # –∫–Ω–æ–ø–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏\n","        load_llm_model_btn = gr.Button('–ó–∞–≥—Ä—É–∫–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏')\n","\n","        # —Å—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏\n","        load_llm_model_log = gr.Textbox(\n","            value=f'–ú–æ–¥–µ–ª—å {LLM_MODEL_REPOS[0]} –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è',\n","            label='–°—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏',\n","            lines=6,\n","            )\n","\n","        # –∫–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ ./models –∫—Ä–æ–º–µ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏\n","        with gr.Group():\n","            gr.Markdown('–û—Å–≤–æ–±–æ–¥–∏—Ç—å –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ –ø—É—Ç–µ–º —É–¥–∞–ª–µ–Ω–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∫—Ä–æ–º–µ —Ç–µ–∫—É—â–µ–π –≤—ã–±—Ä–∞–Ω–Ω–æ–π')\n","            clear_llm_folder_btn = gr.Button('–û—á–∏—Å—Ç–∏—Ç—å –ø–∞–ø–∫—É')\n","\n","        # –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞\n","        new_llm_model_repo_btn.click(\n","            fn=add_new_model_repo,\n","            inputs=[new_llm_model_repo, llm_model_repos],\n","            outputs=[curr_llm_model_repo, load_llm_model_log],\n","        ).success(\n","            fn=lambda: '',\n","            inputs=None,\n","            outputs=[new_llm_model_repo],\n","        )\n","\n","        # –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π GGUF –∏–∑ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è\n","        curr_llm_model_repo.change(\n","            fn=get_gguf_model_names,\n","            inputs=[curr_llm_model_repo],\n","            outputs=[curr_llm_model_path],\n","        )\n","\n","        # –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–∏ GGUF\n","        load_llm_model_btn.click(\n","            fn=load_llm_model,\n","            inputs=[curr_llm_model_repo, curr_llm_model_path],\n","            outputs=[llm_model, support_system_role, load_llm_model_log],\n","        ).success(\n","            fn=lambda log: log + get_memory_usage(),\n","            inputs=[load_llm_model_log],\n","            outputs=[load_llm_model_log],\n","        ).then(\n","            fn=get_system_prompt_component,\n","            inputs=[support_system_role],\n","            outputs=[system_prompt],\n","        )\n","\n","        # –æ—á–∏—Å—Ç–∫–∞ –ø–∞–ø–∫–∏ —Å –º–æ–¥–µ–ª—è–º–∏ –∫—Ä–æ–º–µ —Ç–µ–∫—É—â–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π\n","        clear_llm_folder_btn.click(\n","            fn=clear_llm_folder,\n","            inputs=[curr_llm_model_path],\n","            outputs=None,\n","        ).success(\n","            fn=lambda model_path: f'–ú–æ–¥–µ–ª–∏ –∫—Ä–æ–º–µ {model_path} —É–¥–∞–ª–µ–Ω—ã',\n","            inputs=[curr_llm_model_path],\n","            outputs=None,\n","        )\n","\n","\n","    # ================= –°–¢–†–ê–ù–ò–¶–ê –ó–ê–ì–†–£–ó–ö–ò –≠–ú–ë–ï–î–ò–ù–ì –ú–û–î–ï–õ–ï–ô =============\n","\n","    with gr.Tab('Load embed model'):\n","        # –æ–∫–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤–æ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è —Å HF\n","        new_embed_model_repo = gr.Textbox(\n","            value='',\n","            label='–î–æ–±–∞–≤–∏—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π',\n","            placeholder='–°—Å—ã–ª–∫–∞ –Ω–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –º–æ–¥–µ–ª–∏ HF',\n","            )\n","        new_embed_model_repo_btn = gr.Button('–î–æ–±–∞–≤–∏—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π')\n","\n","        # –≤—ã–±–æ—Ä —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è HF –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö\n","        curr_embed_model_repo = gr.Dropdown(\n","            choices=EMBED_MODEL_REPOS,\n","            value=None,\n","            label='–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –º–æ–¥–µ–ª–∏ HF',\n","            )\n","\n","        # —Å—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏\n","        load_embed_model_btn = gr.Button('–ó–∞–≥—Ä—É–∫–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏')\n","        load_embed_model_log = gr.Textbox(\n","            value=f'–ú–æ–¥–µ–ª—å {EMBED_MODEL_REPOS[0]} –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é',\n","            label='–°—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏',\n","            lines=7,\n","            )\n","        with gr.Group():\n","            gr.Markdown('–û—Å–≤–æ–±–æ–¥–∏—Ç—å –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ –ø—É—Ç–µ–º —É–¥–∞–ª–µ–Ω–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∫—Ä–æ–º–µ —Ç–µ–∫—É—â–µ–π –≤—ã–±—Ä–∞–Ω–Ω–æ–π')\n","            clear_embed_folder_btn = gr.Button('–û—á–∏—Å—Ç–∏—Ç—å –ø–∞–ø–∫—É')\n","\n","        # –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞\n","        new_embed_model_repo_btn.click(\n","            fn=add_new_model_repo,\n","            inputs=[new_embed_model_repo, embed_model_repos],\n","            outputs=[curr_embed_model_repo, load_embed_model_log],\n","        ).success(\n","            fn=lambda: '',\n","            inputs=None,\n","            outputs=new_embed_model_repo,\n","        )\n","\n","        # –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤\n","        load_embed_model_btn.click(\n","            fn=load_embed_model,\n","            inputs=[curr_embed_model_repo],\n","            outputs=[embed_model, load_embed_model_log],\n","        ).success(\n","            fn=lambda log: log + get_memory_usage(),\n","            inputs=[load_embed_model_log],\n","            outputs=[load_embed_model_log],\n","        )\n","\n","        # –æ—á–∏—Å—Ç–∫–∞ –ø–∞–ø–∫–∏ —Å –º–æ–¥–µ–ª—è–º–∏ –∫—Ä–æ–º–µ —Ç–µ–∫—É—â–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π\n","        clear_embed_folder_btn.click(\n","            fn=clear_embed_folder,\n","            inputs=[curr_embed_model_repo],\n","            outputs=None,\n","        ).success(\n","            fn=lambda model_repo: f'–ú–æ–¥–µ–ª–∏ –∫—Ä–æ–º–µ {model_repo} —É–¥–∞–ª–µ–Ω—ã',\n","            inputs=[curr_embed_model_repo],\n","            outputs=None,\n","        )\n","\n","# –∑–∞–ø—É—Å–∫ –≤ Colab\n","interface.launch(debug=True)\n","\n","# –∑–∞–ø—É—Å–∫ –Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–∞—à–∏–Ω–µ, —É–¥–∞–ª–µ–Ω–Ω–æ–º —Å–µ—Ä–≤–µ—Ä–µ –∏–ª–∏ –≤ Docker\n","# interface.launch(server_name='0.0.0.0', server_port=7860)  # debug=True"],"metadata":{"id":"HcJJK_3K8A1_","colab":{"base_uri":"https://localhost:8080/","height":660},"outputId":"5aae4408-30ff-4f16-b265-995778d8fedf","executionInfo":{"status":"ok","timestamp":1728638109706,"user_tz":-180,"elapsed":327971,"user":{"displayName":"–°–µ—Ä–≥–µ–π","userId":"08873757262896960569"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://efb275976fd581d286.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://efb275976fd581d286.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:7860 <> https://efb275976fd581d286.gradio.live\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["# Docker"],"metadata":{"id":"hK89gjq0Ksmb"}},{"cell_type":"markdown","source":["–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –∫—Ä–æ–º–µ `*docker*` —Ç–∞–∫–æ–µ –∂–µ –∫–∞–∫ –≤ —Ä–∞–∑–¥–µ–ª–µ `–ü–æ–ª–Ω—ã–π –∫–æ–¥ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è` –≤—ã—à–µ"],"metadata":{"id":"miTbW2Whzomq"}},{"cell_type":"markdown","source":["–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –æ–±—Ä–∞–∑–∞–º Docker –¥–ª—è `llama-cpp-python`  \n","https://github.com/abetlen/llama-cpp-python/tree/main/docker\n","\n","–û–±—Ä–∞–∑—ã Nvidia CUDA  \n","https://catalog.ngc.nvidia.com/orgs/nvidia/containers/cuda/tags\n","\n","–û–±—Ä–∞–∑—ã Pytorch –æ—Ç Nvidia  \n","https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch/tags\n","\n","–û–±—Ä–∞–∑—ã Pytorch –Ω–∞ Docker Hub  \n","https://hub.docker.com/r/pytorch/pytorch/tags\n"],"metadata":{"id":"TvDqqUiVuWMw"}},{"cell_type":"markdown","source":["**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞:**\n","\n"," - üìÅ `embed_models`\n"," - üìÅ `models`\n"," - `.dockerignore`\n"," - `Dockerfile-cpu`\n"," - `Dockerfile-cuda`\n"," - `requirements-base.txt`\n"," - `requirements-cpu.txt`\n"," - `requirements-cuda.txt`\n"," - `app.py`\n"," - `config.py`\n"," - `utils.py`\n","\n"],"metadata":{"id":"mzcjNqzXxqlv"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"hviJmPRoImqG"}},{"cell_type":"markdown","source":["**–°–±–æ—Ä–∫–∞ –æ–±—Ä–∞–∑–∞ –∏ –∑–∞–ø—É—Å–∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞:**\n","\n","1) –°–±–æ—Ä–∫–∞ –æ–±—Ä–∞–∑–∞  \n","\n"," - —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CPU\n","```\n","docker build -t chatbot-rag:cpu -f Dockerfile-cpu .\n","```\n"," - —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA\n","```\n","docker build -t chatbot-rag:cuda -f Dockerfile-cuda .\n","```\n","\n","2) –ó–∞–ø—É—Å–∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –Ω–∞ 7860 –ø–æ—Ä—Ç—É —Å –ø—Ä–æ–±—Ä–æ—Å–æ–º –ø–∞–ø–æ–∫ —á–µ—Ä–µ–∑ `docker volumes`\n"," - —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CPU\n","```\n","docker run -it -p 7860:7860 \\\n","\t-v ./embed_models:/app/embed_models \\\n","\t-v ./models:/app/models \\\n","\t--name chatbot-rag \\\n","\tchatbot-rag:cpu\n","```\n","\n"," - —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA\n","```\n","docker run -it --gpus all -p 7860:7860 \\\n","\t-v ./embed_models:/app/embed_models \\\n","\t-v ./models:/app/models \\\n","\t--name chatbot-rag \\\n","\tchatbot-rag:cuda\n","```\n","\n","3) –ü–µ—Ä–µ–π—Ç–∏ –≤ –±—Ä–∞—É–∑–µ—Ä–µ http://localhost:7860/ –ø–æ—Å–ª–µ —Ç–æ–≥–æ –∫–∞–∫ –ø–æ—è–≤–∏—Ç—Å—è –Ω–∞–¥–ø–∏—Å—å `Running on local URL:  http://0.0.0.0:7860`"],"metadata":{"id":"p-7rkxCW5X_J"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"2OD3hVK1Ild_"}},{"cell_type":"markdown","source":["**–°–æ–¥–µ—Ä–∂–∏–º–æ–µ `Dockerfile-cpu`**\n","```\n","FROM python:3.10\n","WORKDIR /app\n","RUN pip install --no-cache-dir llama_cpp_python==0.2.88\n","COPY requirements-cpu.txt requirements-base.txt .\n","RUN pip install --no-cache-dir -r requirements-cpu.txt\n","COPY app.py config.py utils.py .\n","EXPOSE 7860\n","CMD [\"python3\", \"app.py\"]\n","```\n","–ó–¥–µ—Å—å `llama_cpp_python` —Å—Ç–∞–≤–∏—Ç—Å—è –∑–∞—Ä–∞–Ω–µ–µ –æ—Ç–¥–µ–ª—å–Ω–æ –ø–æ—Ç–æ–º—É —á—Ç–æ –∏–Ω–∞—á–µ –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ —á–µ—Ä–µ–∑ `whl` (–∫–∞–∫ —É–∫–∞–∑–∞–Ω–æ –≤ `reuirements.txt`) –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ –≤–æ–∑–Ω–∏–∫–∞–ª–∞ –æ—à–∏–±–∫–∞  \n","`Failed to load shared library '/usr/local/lib/python3.10/site-packages/llama_cpp/lib/libllama.so': libc.musl-x86_64.so.1: cannot open shared object fil`  \n","–ú–æ–∂–Ω–æ –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å —ç—Ç–∏ –∫–æ–º–∞–Ω–¥—ã –≤ –æ–¥–Ω—É –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ä–∞–∑–º–µ—Ä–∞ –æ–±—Ä–∞–∑–∞ (—Ä–∞–∑–Ω–∏—Ü—ã –≤ —Ä–∞–∑–º–µ—Ä–µ –Ω–µ—Ç)"],"metadata":{"id":"VfzlfUyi1BmY"}},{"cell_type":"markdown","source":["–ù–µ—Å–∂–∞—Ç—ã–π –æ–±—Ä–∞–∑ CPU –∑–∞–Ω–∏–º–∞–µ—Ç 2.73 GB, —Å–∂–∞—Ç—ã–π 854 MB  "],"metadata":{"id":"kgouqKX2IkJd"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"5e_3h2vMIdmp"}},{"cell_type":"markdown","source":["**–°–æ–¥–µ—Ä–∂–∏–º–æ–µ `Dockerfile-cuda` –≤–∞—Ä–∏–∞–Ω—Ç —á–µ—Ä–µ–∑ –æ–±—Ä–∞–∑—ã `nvidia/cuda`**\n","```\n","ARG CUDA_IMAGE=\"12.5.0-devel-ubuntu22.04\"\n","FROM nvidia/cuda:${CUDA_IMAGE} AS builder\n","\n","RUN apt-get update \\\n","    && apt-get install -y python3 python3-pip \\\n","    && apt-get clean && rm -rf /var/lib/apt/lists/*\n","\n","ENV CUDA_DOCKER_ARCH=all\n","ENV GGML_CUDA=1\n","ENV CMAKE_ARGS=\"-DGGML_CUDA=on\"\n","\n","RUN pip install --no-cache-dir llama_cpp_python==0.2.88\n","COPY requirements-base.txt requirements-cuda.txt .\n","RUN pip install --no-cache-dir -r requirements-cuda.txt\n","\n","ARG CUDA_IMAGE=\"12.5.0-runtime-ubuntu22.04\"\n","FROM nvidia/cuda:${CUDA_IMAGE}\n","\n","RUN apt-get update \\\n","    && apt-get install -y python3 python3-pip \\\n","    && apt-get clean && rm -rf /var/lib/apt/lists/*\n","\n","ARG PYTHON_VERSION=3.10\n","COPY --from=builder /usr/local/lib/python${PYTHON_VERSION}/dist-packages /usr/local/lib/python${PYTHON_VERSION}/dist-packages\n","\n","WORKDIR /app\n","COPY app.py config.py utils.py .\n","EXPOSE 7860\n","CMD [\"python3\", \"app.py\"]\n","```"],"metadata":{"id":"A_q0Q48R3oBu"}},{"cell_type":"markdown","source":["\n","–ù–µ—Å–∂–∞—Ç—ã–π –æ–±—Ä–∞–∑ CUDA –∑–∞–Ω–∏–º–∞–µ—Ç 13.7 GB, —Å–∂–∞—Ç—ã–π 6.81 GB  "],"metadata":{"id":"Zmw1popXeDLU"}},{"cell_type":"markdown","source":["–î–ª—è –¥—Ä—É–≥–∏—Ö –≤–µ—Ä—Å–∏–π CUDA –∑–∞–º–µ–Ω–∏—Ç—å –≤ `Dockerfile-cuda` —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –±–∞–∑–æ–≤—ã–µ –æ–±—Ä–∞–∑—ã –≤–º–µ—Å—Ç–æ  \n","```\n","ARG CUDA_IMAGE=\"12.5.0-devel-ubuntu22.04\"\n","ARG CUDA_IMAGE=\"12.5.0-runtime-ubuntu22.04\"\n","```"],"metadata":{"id":"9TkzXoLDEwB7"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"kEEsdE_wIM7b"}},{"cell_type":"markdown","source":["**–°–æ–¥–µ—Ä–∂–∏–º–æ–µ `Dockerfile-cuda` –≤–∞—Ä–∏–∞–Ω—Ç —á–µ—Ä–µ–∑ –æ–±—Ä–∞–∑—ã `pytorch/pytorch`**\n","```\n","FROM pytorch/pytorch:2.4.1-cuda12.4-cudnn9-devel AS builder\n","\n","ENV CUDA_DOCKER_ARCH=all\n","ENV GGML_CUDA=1\n","ENV CMAKE_ARGS=\"-DGGML_CUDA=on\"\n","\n","COPY requirements-base.txt .\n","RUN pip wheel --no-cache-dir --no-deps --wheel-dir /app/wheels llama_cpp_python==0.2.88 && \\\n","    pip wheel --no-cache-dir --no-deps --wheel-dir /app/wheels -r requirements-base.txt\n","\n","FROM pytorch/pytorch:2.4.1-cuda12.4-cudnn9-runtime\n","WORKDIR /app\n","\n","COPY --from=builder /app/wheels /wheels\n","RUN pip install --no-cache-dir /wheels/*\n","\n","COPY app.py config.py utils.py .\n","\n","EXPOSE 7860\n","CMD [\"python3\", \"app.py\"]\n","```"],"metadata":{"id":"ByiJnF90lqde"}},{"cell_type":"markdown","source":["–ù–µ—Å–∂–∞—Ç—ã–π –æ–±—Ä–∞–∑ CUDA –∑–∞–Ω–∏–º–∞–µ—Ç 7.77 GB, —Å–∂–∞—Ç—ã–π 3.77 GB"],"metadata":{"id":"gsS9MQHlIUz2"}},{"cell_type":"markdown","source":["# –ü—Ä–æ—á–µ–µ"],"metadata":{"id":"CXaXu9agKbO7"}},{"cell_type":"markdown","source":["–ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–µ–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ GGUF —á–µ—Ä–µ–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫—É `llama-cpp-python`"],"metadata":{"id":"Sb21bITRN1vw"}},{"cell_type":"markdown","source":["–§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫—É `requests` —Å –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä–æ–º"],"metadata":{"id":"Bp2YuApLsKrs"}},{"cell_type":"code","source":["def download_file(file_url: str, file_path: Union[str, Path]) -> None:\n","    response = requests.get(file_url, stream=True)\n","    total_size = int(response.headers.get('content-length', 0))\n","    chunk_size = 4096  # 4 Kb\n","    progress_bar = tqdm(desc='–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ GGUF', total=total_size, unit='iB', unit_scale=True)\n","\n","    with open(file_path, 'wb') as file:\n","        for data in response.iter_content(chunk_size):\n","            file.write(data)\n","            progress_bar.update(len(data))\n","    # progress_bar.close()"],"metadata":{"id":"LX5M0sl2nks0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["–ò–Ω–∏–π—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –µ–º–±–µ–¥–∏–Ω–≥–æ–≤ –∏ LLM –º–æ–¥–µ–ª–∏"],"metadata":{"id":"UPh1kts9J53P"}},{"cell_type":"code","source":["# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤\n","print('–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ ...')\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","embed_model_name = 'sentence-transformers/all-mpnet-base-v2'\n","embed_model_path = Path('embed_models')\n","embed_model = HuggingFaceEmbeddings(\n","    model_name=embed_model_name,\n","    model_kwargs={'device': device},  # cpu cuda\n","    cache_folder=str(embed_model_path),\n","    )\n","\n","# –ø—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ –º–æ–¥–µ–ª—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ GGUF\n","# llm_model_url = 'https://huggingface.co/bartowski/openchat-3.6-8b-20240522-GGUF/resolve/main/openchat-3.6-8b-20240522-IQ4_XS.gguf'\n","llm_model_url = 'https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/gemma-2-2b-it-Q8_0.gguf'\n","\n","# –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –¥–æ –º–æ–¥–µ–ª–∏ –≤ –ø–∞–ø–∫–µ ./models\n","llm_model_path = Path('models') / llm_model_url.rsplit('/')[-1]\n","llm_model_path.parent.mkdir(exist_ok=True)\n","\n","# –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –ø–∞–ø–∫–µ models —Ç–æ –Ω—É–∂–Ω–æ –µ–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å - –Ω–∞–ø—Ä–∏–º–µ—Ä —á–µ—Ä–µ–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫—É wget\n","if not llm_model_path.is_file():\n","    if not str(llm_model_url).endswith('.gguf'):\n","        raise Exception('–°—Å—ã–ª–∫–∞ –Ω–∞ –º–æ–¥–µ–ª—å LLM –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø—Ä—è–º–æ–π —Å—Å—ã–ª–∫–æ–π –Ω–∞ —Ñ–∞–π–ª GGUF')\n","    else:\n","        print('–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ LLM –º–æ–¥–µ–ª–∏ ...')\n","        download_file(llm_model_url, llm_model_path)\n","        # model_path = wget.download(llm_model_url, out=str(llm_model_path))\n","\n","# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ (—É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –Ω—É–∂–Ω—ã–π –∏–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ n_ctx)\n","print('–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM –º–æ–¥–µ–ª–∏ ...')\n","llm_model = Llama(model_path=str(llm_model_path), n_gpu_layers=-1, verbose=True)\n","\n","# –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª–∏ –º–æ–¥–µ–ª—å —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç\n","support_system_role = 'System role not supported' not in llm_model.metadata['tokenizer.chat_template']\n","\n","# –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n","# —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –æ—Ç–≤–µ—á–∞–ª–∞ –æ–¥–∏–Ω–∞–∫–æ–≤–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–æ—Å—Ç–∞–≤–∏—Ç—å top_k=1, top_p=0 –∏ repeat_penalty=1 –Ω–µ –∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n","GENERATE_KWARGS = dict(\n","    temperature=1,  # —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Å–æ—Ñ—Ç–º–∞–∫—Å–∞\n","    top_p=0.0,  # —Å—É–º–º–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Ç–æ–∫–µ–Ω–æ–≤ –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –Ω—É–∂–Ω–æ –≤—ã–±–∏—Ä–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω\n","    top_k=1,  # –∏–∑ —Å–∫–æ–ª—å–∫–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤—ã–±–∏—Ä–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω\n","    repeat_penalty=1.0,  # —à—Ç—Ä–∞—Ñ –º–æ–¥–µ–ª–∏ –∑–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è\n","    )"],"metadata":{"id":"8zuh3PjbJW0B","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5d9e33a4-1dce-48ce-dc4b-3701e4324bae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ ...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","llama_model_loader: loaded meta data with 39 key-value pairs and 288 tensors from model/gemma-2-2b-it-Q8_0.gguf (version GGUF V3 (latest))\n","llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n","llama_model_loader: - kv   0:                       general.architecture str              = gemma2\n","llama_model_loader: - kv   1:                               general.type str              = model\n","llama_model_loader: - kv   2:                               general.name str              = Gemma 2 2b It\n","llama_model_loader: - kv   3:                           general.finetune str              = it\n","llama_model_loader: - kv   4:                           general.basename str              = gemma-2\n","llama_model_loader: - kv   5:                         general.size_label str              = 2B\n","llama_model_loader: - kv   6:                            general.license str              = gemma\n","llama_model_loader: - kv   7:                               general.tags arr[str,2]       = [\"conversational\", \"text-generation\"]\n","llama_model_loader: - kv   8:                      gemma2.context_length u32              = 8192\n","llama_model_loader: - kv   9:                    gemma2.embedding_length u32              = 2304\n","llama_model_loader: - kv  10:                         gemma2.block_count u32              = 26\n","llama_model_loader: - kv  11:                 gemma2.feed_forward_length u32              = 9216\n","llama_model_loader: - kv  12:                gemma2.attention.head_count u32              = 8\n","llama_model_loader: - kv  13:             gemma2.attention.head_count_kv u32              = 4\n","llama_model_loader: - kv  14:    gemma2.attention.layer_norm_rms_epsilon f32              = 0.000001\n","llama_model_loader: - kv  15:                gemma2.attention.key_length u32              = 256\n","llama_model_loader: - kv  16:              gemma2.attention.value_length u32              = 256\n","llama_model_loader: - kv  17:                          general.file_type u32              = 7\n","llama_model_loader: - kv  18:              gemma2.attn_logit_softcapping f32              = 50.000000\n","llama_model_loader: - kv  19:             gemma2.final_logit_softcapping f32              = 30.000000\n","llama_model_loader: - kv  20:            gemma2.attention.sliding_window u32              = 4096\n","llama_model_loader: - kv  21:                       tokenizer.ggml.model str              = llama\n","llama_model_loader: - kv  22:                         tokenizer.ggml.pre str              = default\n"]},{"output_type":"stream","name":"stdout","text":["–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM –º–æ–¥–µ–ª–∏ ...\n"]},{"output_type":"stream","name":"stderr","text":["llama_model_loader: - kv  23:                      tokenizer.ggml.tokens arr[str,256000]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n","llama_model_loader: - kv  24:                      tokenizer.ggml.scores arr[f32,256000]  = [-1000.000000, -1000.000000, -1000.00...\n","llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,256000]  = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n","llama_model_loader: - kv  26:                tokenizer.ggml.bos_token_id u32              = 2\n","llama_model_loader: - kv  27:                tokenizer.ggml.eos_token_id u32              = 1\n","llama_model_loader: - kv  28:            tokenizer.ggml.unknown_token_id u32              = 3\n","llama_model_loader: - kv  29:            tokenizer.ggml.padding_token_id u32              = 0\n","llama_model_loader: - kv  30:               tokenizer.ggml.add_bos_token bool             = true\n","llama_model_loader: - kv  31:               tokenizer.ggml.add_eos_token bool             = false\n","llama_model_loader: - kv  32:                    tokenizer.chat_template str              = {{ bos_token }}{% if messages[0]['rol...\n","llama_model_loader: - kv  33:            tokenizer.ggml.add_space_prefix bool             = false\n","llama_model_loader: - kv  34:               general.quantization_version u32              = 2\n","llama_model_loader: - kv  35:                      quantize.imatrix.file str              = /models_out/gemma-2-2b-it-GGUF/gemma-...\n","llama_model_loader: - kv  36:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n","llama_model_loader: - kv  37:             quantize.imatrix.entries_count i32              = 182\n","llama_model_loader: - kv  38:              quantize.imatrix.chunks_count i32              = 128\n","llama_model_loader: - type  f32:  105 tensors\n","llama_model_loader: - type q8_0:  183 tensors\n","llm_load_vocab: special tokens cache size = 249\n","llm_load_vocab: token to piece cache size = 1.6014 MB\n","llm_load_print_meta: format           = GGUF V3 (latest)\n","llm_load_print_meta: arch             = gemma2\n","llm_load_print_meta: vocab type       = SPM\n","llm_load_print_meta: n_vocab          = 256000\n","llm_load_print_meta: n_merges         = 0\n","llm_load_print_meta: vocab_only       = 0\n","llm_load_print_meta: n_ctx_train      = 8192\n","llm_load_print_meta: n_embd           = 2304\n","llm_load_print_meta: n_layer          = 26\n","llm_load_print_meta: n_head           = 8\n","llm_load_print_meta: n_head_kv        = 4\n","llm_load_print_meta: n_rot            = 256\n","llm_load_print_meta: n_swa            = 4096\n","llm_load_print_meta: n_embd_head_k    = 256\n","llm_load_print_meta: n_embd_head_v    = 256\n","llm_load_print_meta: n_gqa            = 2\n","llm_load_print_meta: n_embd_k_gqa     = 1024\n","llm_load_print_meta: n_embd_v_gqa     = 1024\n","llm_load_print_meta: f_norm_eps       = 0.0e+00\n","llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n","llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n","llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n","llm_load_print_meta: f_logit_scale    = 0.0e+00\n","llm_load_print_meta: n_ff             = 9216\n","llm_load_print_meta: n_expert         = 0\n","llm_load_print_meta: n_expert_used    = 0\n","llm_load_print_meta: causal attn      = 1\n","llm_load_print_meta: pooling type     = 0\n","llm_load_print_meta: rope type        = 2\n","llm_load_print_meta: rope scaling     = linear\n","llm_load_print_meta: freq_base_train  = 10000.0\n","llm_load_print_meta: freq_scale_train = 1\n","llm_load_print_meta: n_ctx_orig_yarn  = 8192\n","llm_load_print_meta: rope_finetuned   = unknown\n","llm_load_print_meta: ssm_d_conv       = 0\n","llm_load_print_meta: ssm_d_inner      = 0\n","llm_load_print_meta: ssm_d_state      = 0\n","llm_load_print_meta: ssm_dt_rank      = 0\n","llm_load_print_meta: model type       = 2B\n","llm_load_print_meta: model ftype      = Q8_0\n","llm_load_print_meta: model params     = 2.61 B\n","llm_load_print_meta: model size       = 2.59 GiB (8.50 BPW) \n","llm_load_print_meta: general.name     = Gemma 2 2b It\n","llm_load_print_meta: BOS token        = 2 '<bos>'\n","llm_load_print_meta: EOS token        = 1 '<eos>'\n","llm_load_print_meta: UNK token        = 3 '<unk>'\n","llm_load_print_meta: PAD token        = 0 '<pad>'\n","llm_load_print_meta: LF token         = 227 '<0x0A>'\n","llm_load_print_meta: EOT token        = 107 '<end_of_turn>'\n","llm_load_print_meta: max token length = 48\n","llm_load_tensors: ggml ctx size =    0.13 MiB\n","llm_load_tensors:        CPU buffer size =  2649.74 MiB\n","..................................................................\n","llama_new_context_with_model: n_ctx      = 4096\n","llama_new_context_with_model: n_batch    = 512\n","llama_new_context_with_model: n_ubatch   = 512\n","llama_new_context_with_model: flash_attn = 0\n","llama_new_context_with_model: freq_base  = 10000.0\n","llama_new_context_with_model: freq_scale = 1\n","llama_kv_cache_init:        CPU KV buffer size =   416.00 MiB\n","llama_new_context_with_model: KV self size  =  416.00 MiB, K (f16):  208.00 MiB, V (f16):  208.00 MiB\n","llama_new_context_with_model:        CPU  output buffer size =     0.98 MiB\n","llama_new_context_with_model:        CPU compute buffer size =   504.50 MiB\n","llama_new_context_with_model: graph nodes  = 1050\n","llama_new_context_with_model: graph splits = 1\n","AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n","Model metadata: {'quantize.imatrix.chunks_count': '128', 'quantize.imatrix.entries_count': '182', 'general.quantization_version': '2', 'quantize.imatrix.file': '/models_out/gemma-2-2b-it-GGUF/gemma-2-2b-it.imatrix', 'tokenizer.ggml.add_space_prefix': 'false', 'gemma2.attention.head_count': '8', 'gemma2.feed_forward_length': '9216', 'gemma2.block_count': '26', 'tokenizer.ggml.pre': 'default', 'general.license': 'gemma', 'general.type': 'model', 'gemma2.embedding_length': '2304', 'general.basename': 'gemma-2', 'tokenizer.ggml.padding_token_id': '0', 'gemma2.context_length': '8192', 'tokenizer.chat_template': \"{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\\n' + message['content'] | trim + '<end_of_turn>\\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\\n'}}{% endif %}\", 'general.architecture': 'gemma2', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'gemma2.attention.key_length': '256', 'gemma2.attention.value_length': '256', 'gemma2.attention.layer_norm_rms_epsilon': '0.000001', 'general.finetune': 'it', 'general.file_type': '7', 'gemma2.attention.sliding_window': '4096', 'gemma2.attn_logit_softcapping': '50.000000', 'gemma2.final_logit_softcapping': '30.000000', 'gemma2.attention.head_count_kv': '4', 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.model': 'llama', 'general.name': 'Gemma 2 2b It', 'tokenizer.ggml.bos_token_id': '2', 'tokenizer.ggml.eos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '3', 'general.size_label': '2B', 'tokenizer.ggml.add_bos_token': 'true'}\n","Available chat formats from metadata: chat_template.default\n","Using gguf chat template: {{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n","' + message['content'] | trim + '<end_of_turn>\n","' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n","'}}{% endif %}\n","Using chat eos_token: <eos>\n","Using chat bos_token: <bos>\n"]}]},{"cell_type":"markdown","source":["–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –º–æ–¥–µ–ª—å—é\n","\n","–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –º–µ—Ç–æ–¥—É `create_chat_completion`  \n","https://llama-cpp-python.readthedocs.io/en/latest/api-reference/#llama_cpp.Llama.create_chat_completion"],"metadata":{"id":"xyvdcWVcJ8wq"}},{"cell_type":"code","source":["%%time\n","\n","# –≤—Ö–æ–¥–Ω–æ–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n","user_message = '–ü–æ—á–µ–º—É —Ç—Ä–∞–≤–∞ –∑–µ–ª–µ–Ω–∞—è?'\n","# —Å–ø–∏—Å–æ–∫ —Å —Ä–µ–ø–ª–∏–∫–∞–º–∏ —é–∑–µ—Ä–∞ –∏ –±–æ—Ç–∞ (–≤ –¥–∞–Ω–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ –æ–¥–Ω–∞)\n","messages = []\n","# —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –ø—Ä–æ–º—Ç–∞ —Å –∑–∞–ø—Ä–æ—Å–æ–º –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n","messages.append({'role': 'user', 'content': user_message})\n","\n","# –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n","# —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –æ—Ç–≤–µ—á–∞–ª–∞ –æ–¥–∏–Ω–∞–∫–æ–≤–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–æ—Å—Ç–∞–≤–∏—Ç—å top_k=1, top_p=0 –∏ repeat_penalty=1 –Ω–µ –∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n","GENERATE_KWARGS = dict(\n","    temperature=1,  # —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Å–æ—Ñ—Ç–º–∞–∫—Å–∞\n","    top_p=0.0,  # —Å—É–º–º–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Ç–æ–∫–µ–Ω–æ–≤ –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –Ω—É–∂–Ω–æ –≤—ã–±–∏—Ä–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω\n","    top_k=1,  # –∏–∑ —Å–∫–æ–ª—å–∫–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤—ã–±–∏—Ä–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω\n","    repeat_penalty=1.0,  # —à—Ç—Ä–∞—Ñ –º–æ–¥–µ–ª–∏ –∑–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è\n","    )\n","\n","# —Å–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –∏—Ç–µ—Ä–∞—Ç–æ—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞\n","# –ø—Ä–∏ –∏—Ç–µ—Ä–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –æ–±—ä–µ–∫—Ç—É –≤ —Ü–∏–∫–ª–µ –æ–Ω–∞ –±—É–¥–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —á–∞—Å—Ç—è–º–∏ —Ç–µ–∫—Å—Ç–∞ (—Ç–æ–∫–µ–Ω–∞–º–∏)\n","stream_response = llm_model.create_chat_completion(\n","    messages=messages,  # –≤—Ö–æ–¥–Ω–æ–π –ø—Ä–æ–º—Ç –Ω–∞ –∫–æ—Ç–æ—Ä—ã–π –Ω–∞–¥–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç\n","    stream=True,  # –≤–µ—Ä–Ω—É—Ç—å –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä\n","    **GENERATE_KWARGS,  # –ø–µ—Ä–µ–¥–∞—á–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n","    )\n","\n","# –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –±—É–¥–µ–º –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä–æ–≤–∞—Ç—å —Å —Ç–æ–∫–µ–Ω–∞–º–∏ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏\n","response_text = ''\n","# –∏—Ç–µ—Ä–∞—Ü–∏—è –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –º–æ–¥–µ–ª—å—é –≤ —Ü–∏–∫–ª–µ\n","for chunk in stream_response:\n","    # –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞\n","    token = chunk['choices'][0]['delta'].get('content')\n","    if token is not None:\n","        response_text += token\n","        print(token, end='')"],"metadata":{"id":"Ng99Cz76ryrA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ed263ad3-cd94-4c9b-dc5a-433e8ccb2bb7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["–¢—Ä–∞–≤–∞ –∑–µ–ª–µ–Ω–∞—è –∏–∑-–∑–∞ –ø–∏–≥–º–µ–Ω—Ç–∞ **—Ö–ª–æ—Ä–æ—Ñ–∏–ª–ª–∞**. \n","\n","–í–æ—Ç –∫–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:\n","\n","* **–•–ª–æ—Ä–æ—Ñ–∏–ª–ª** - —ç—Ç–æ –ø–∏–≥–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –≤ —Ö–ª–æ—Ä–æ–ø–ª–∞—Å—Ç–∞—Ö, –æ—Ä–≥–∞–Ω–µ–ª–ª–∞—Ö, —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω—ã—Ö –≤ –∫–ª–µ—Ç–∫–∞—Ö —Ä–∞—Å—Ç–µ–Ω–∏–π. \n","* **–•–ª–æ—Ä–æ—Ñ–∏–ª–ª** –ø–æ–≥–ª–æ—â–∞–µ—Ç —Å–æ–ª–Ω–µ—á–Ω—ã–π —Å–≤–µ—Ç, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ –∫—Ä–∞—Å–Ω–æ–º –∏ —Å–∏–Ω–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ, –∏ –æ—Ç—Ä–∞–∂–∞–µ—Ç –∑–µ–ª–µ–Ω—ã–π —Å–≤–µ—Ç. \n","* **–ó–µ–ª–µ–Ω—ã–π —Å–≤–µ—Ç** - —ç—Ç–æ —Ç–æ, —á—Ç–æ –º—ã –≤–∏–¥–∏–º, –∫–æ–≥–¥–∞ —Ç—Ä–∞–≤–∞ –æ—Ç—Ä–∞–∂–∞–µ—Ç —Å–≤–µ—Ç. \n","\n","–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —Ç—Ä–∞–≤–∞ –∫–∞–∂–µ—Ç—Å—è –∑–µ–ª–µ–Ω–æ–π, –ø–æ—Ç–æ–º—É —á—Ç–æ –æ–Ω–∞ –æ—Ç—Ä–∞–∂–∞–µ—Ç –∑–µ–ª–µ–Ω—ã–π —Å–≤–µ—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–≥–ª–æ—â–∞–µ—Ç—Å—è —Ö–ª–æ—Ä–æ—Ñ–∏–ª–ª–æ–º. \n"]},{"output_type":"stream","name":"stderr","text":["\n","llama_print_timings:        load time =   14636.85 ms\n","llama_print_timings:      sample time =      45.09 ms /   149 runs   (    0.30 ms per token,  3304.50 tokens per second)\n","llama_print_timings: prompt eval time =   14631.99 ms /    15 tokens (  975.47 ms per token,     1.03 tokens per second)\n","llama_print_timings:        eval time =   76900.53 ms /   148 runs   (  519.60 ms per token,     1.92 tokens per second)\n","llama_print_timings:       total time =   92487.25 ms /   163 tokens\n"]},{"output_type":"stream","name":"stdout","text":["CPU times: user 1min 12s, sys: 465 ms, total: 1min 12s\n","Wall time: 1min 32s\n"]}]},{"cell_type":"markdown","source":["–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ"],"metadata":{"id":"5kqpWoXJJBmt"}},{"cell_type":"markdown","source":["–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–≥–æ–≥–æ –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ –º–µ—Ç–æ–¥—ã `similarity_search`"],"metadata":{"id":"dqvH-FfKJC6y"}},{"cell_type":"markdown","source":["–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤"],"metadata":{"id":"fOfFFqnlJZ8b"}},{"cell_type":"code","source":["# model_name = 'inkoziev/sbert_pq'\n","# model_name = 'sergeyzh/LaBSE-ru-turbo'\n","model_name = 'intfloat/multilingual-e5-small'\n","\n","embed_model = HuggingFaceEmbeddings(\n","    model_name=model_name,\n","    cache_folder='./embed_models',\n","    # encode_kwargs={'normalize_embeddings': True},  # –¥–æ–ø –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤\n","    )"],"metadata":{"id":"Sfzg2zRT6se1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–∏—Å–∫–∞"],"metadata":{"id":"g9yG_JZBJffO"}},{"cell_type":"code","source":["from langchain_community.vectorstores.utils import DistanceStrategy\n","\n","# –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ë–î\n","docs = [Document(text) for text in ['–∑–∏–º–∞', '–≤–µ—Å–Ω–∞', '–ª–µ—Ç–æ']]\n","\n","# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î\n","db = FAISS.from_documents(\n","    documents=docs,\n","    embedding=embed_model,\n","    normalize_L2=True,\n","    # distance_strategy=DistanceStrategy.COSINE,  # —É–∫–∞–∑–∞—Ç—å –º–µ—Ä—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è\n","    )"],"metadata":{"id":"UgJK49hl6dmb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# —á–∏—Å–ª–æ –æ—Ç 0 –¥–æ 1, —á–µ–º –±–æ–ª—å—à–µ —Ç–µ–º –±–æ–ª–µ–µ –ø–æ—Ö–æ–∂ —Ç–µ–∫—Å—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å (–Ω–∞ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –º–æ–¥–µ–ª—è—Ö —ç—Ç–æ –Ω–µ —Ç–∞–∫)\n","db.similarity_search_with_relevance_scores('f fd ffd &**& $##%^ &% %')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QNwAhmN06dtT","outputId":"522457d3-6671-488a-a0f6-d53ef4f02795"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(Document(metadata={}, page_content='–ª–µ—Ç–æ'), 0.7641452874289455),\n"," (Document(metadata={}, page_content='–∑–∏–º–∞'), 0.753656917736464),\n"," (Document(metadata={}, page_content='–≤–µ—Å–Ω–∞'), 0.7509914456695138)]"]},"metadata":{},"execution_count":212}]},{"cell_type":"code","source":["# –Ω–∞–æ–±–æ—Ä–æ—Ç, —á–µ–º –º–µ–Ω—å—à–µ —á–∏—Å–ª–æ —Ç–µ–º –±–æ–ª–µ–µ –ø–æ—Ö–æ–∂ —Ç–µ–∫—Å—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å\n","db.similarity_search_with_score('f fd ffd &**& $##%^ &% %')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fn9gie6_7E-I","outputId":"9f2626b8-8d34-474b-c725-27e24916cbfd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(Document(metadata={}, page_content='–ª–µ—Ç–æ'), 0.33354893),\n"," (Document(metadata={}, page_content='–∑–∏–º–∞'), 0.34838173),\n"," (Document(metadata={}, page_content='–≤–µ—Å–Ω–∞'), 0.35215127)]"]},"metadata":{},"execution_count":213}]},{"cell_type":"code","source":["db.similarity_search_with_relevance_scores('–≤–µ—Å–µ–ª—å–µ', k=2, score_threshold=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zq-GDgpsFVNd","outputId":"097f4b5d-b115-4ac3-8bf8-431d034cb6f5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(Document(metadata={}, page_content='–≤–µ—Å–Ω–∞'), 0.8463678883149083),\n"," (Document(metadata={}, page_content='–ª–µ—Ç–æ'), 0.8251721117582341)]"]},"metadata":{},"execution_count":214}]},{"cell_type":"code","source":["db.similarity_search_with_score('–≤–µ—Å–µ–ª—å–µ')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jW4Snzn9FVQB","outputId":"c8d9c052-ba31-4e5c-aa7e-a7ca05c0c668"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(Document(metadata={}, page_content='–≤–µ—Å–Ω–∞'), 0.21726862),\n"," (Document(metadata={}, page_content='–ª–µ—Ç–æ'), 0.24724397),\n"," (Document(metadata={}, page_content='–∑–∏–º–∞'), 0.28593075)]"]},"metadata":{},"execution_count":215}]},{"cell_type":"markdown","source":["–ò–∑–º–µ–Ω–µ–Ω–∏–µ –º–µ—Ä—ã —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è"],"metadata":{"id":"m-leRZvxJiLZ"}},{"cell_type":"code","source":["from langchain_community.vectorstores.utils import DistanceStrategy\n","db = FAISS.from_documents(\n","    documents=docs,\n","    embedding=embed_model,\n","    # distance_strategy=DistanceStrategy.COSINE,\n","\n","    # https://github.com/langchain-ai/langchain/issues/9519\n","    distance_strategy=DistanceStrategy.MAX_INNER_PRODUCT,\n","    )"],"metadata":{"id":"04Uwaz6B7Rbo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["db.similarity_search_with_relevance_scores('f fd ffd &**& $##%^ &% %', k=2, score_threshold=0.1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f76a0cdd-81dc-4e27-85a0-645513c92f2b","id":"xZTNqvWp7SWo"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(Document(metadata={}, page_content='–ª–µ—Ç–æ'), 0.16677451133728027),\n"," (Document(metadata={}, page_content='–∑–∏–º–∞'), 0.17419099807739258)]"]},"metadata":{},"execution_count":217}]},{"cell_type":"code","source":["db.similarity_search_with_score('f fd ffd &**& $##%^ &% %')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cb75a6ee-7054-40fe-f6eb-d70a2786cc4b","id":"63_zYcW_7SWp"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(Document(metadata={}, page_content='–ª–µ—Ç–æ'), 0.8332255),\n"," (Document(metadata={}, page_content='–∑–∏–º–∞'), 0.825809),\n"," (Document(metadata={}, page_content='–≤–µ—Å–Ω–∞'), 0.8239243)]"]},"metadata":{},"execution_count":218}]},{"cell_type":"code","source":["db.similarity_search_with_relevance_scores('–≤–µ—Å–µ–ª—å–µ', k=2, score_threshold=0.1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HxVT6ziMFTBS","outputId":"f768de90-7a27-4a99-8e3d-fc430288f31b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(Document(metadata={}, page_content='–≤–µ—Å–Ω–∞'), 0.108634352684021),\n"," (Document(metadata={}, page_content='–ª–µ—Ç–æ'), 0.12362194061279297)]"]},"metadata":{},"execution_count":222}]},{"cell_type":"code","source":["db.similarity_search_with_score('–≤–µ—Å–µ–ª—å–µ')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xk4hgNb_FTEX","outputId":"3bd453c8-4360-4a38-a317-58affa1cd9ed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(Document(metadata={}, page_content='–≤–µ—Å–Ω–∞'), 0.89136565),\n"," (Document(metadata={}, page_content='–ª–µ—Ç–æ'), 0.87637806),\n"," (Document(metadata={}, page_content='–∑–∏–º–∞'), 0.85703456)]"]},"metadata":{},"execution_count":220}]},{"cell_type":"code","source":["db.similarity_search_with_relevance_scores('–≥—Ä—É—Å—Ç—å', k=2, score_threshold=0.1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KY6w-A-DGNmc","outputId":"1ebd6051-9c83-48e5-ca0f-a77f51f34f81"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(Document(metadata={}, page_content='–ª–µ—Ç–æ'), 0.12584853172302246),\n"," (Document(metadata={}, page_content='–≤–µ—Å–Ω–∞'), 0.12598317861557007)]"]},"metadata":{},"execution_count":221}]}],"metadata":{"colab":{"toc_visible":true,"provenance":[],"collapsed_sections":["A7w7hpUsKpM1","o18AOcSERr5l","PVEAYBZ1Cis-","6m1t2-GdKj_B","JR8cnRdHn8ga","vbODSV_KKlv4","hK89gjq0Ksmb","CXaXu9agKbO7"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}