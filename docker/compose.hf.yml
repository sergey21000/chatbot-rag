# единый сервис со скомпилированной llama.cpp для деплоя на HF

services:
  app:
    image: ghcr.io/sergey21000/chatbot-rag:main-hf
    container_name: app
    restart: unless-stopped
    ports:
      - ${GRADIO_SERVER_PORT:-7860}:7860
    volumes:
      - ${LLAMA_CACHE:-../llm_models}:/app/llm_models
      - ${EMBED_MODEL_DIR:-../embed_models}:/app/embed_models
      - ../config.py:/app/config.py
    environment:
      - GRADIO_SERVER_PORT=7860
      - GRADIO_SERVER_NAME=0.0.0.0
      - LLAMA_ARG_PORT=8080
      - LLAMA_ARG_HOST=0.0.0.0
      - LLAMA_CACHE=/app/llm_models
    env_file:
      - path: ../.env
        required: true
